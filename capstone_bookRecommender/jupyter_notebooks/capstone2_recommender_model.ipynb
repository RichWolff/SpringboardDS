{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import re\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''#import plotly for interactive chart\n",
    "import plotly.plotly as py\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='richwolff', api_key='v0qPC120X33yPvAMDQXi')\n",
    "from plotly.graph_objs import * '''\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import defaultdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Load books into dataframe</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = defaultdict(list)\n",
    "\n",
    "strtofind = r'\";\"'\n",
    "with open('../data/raw/BX-Books.csv','r',encoding='8859') as file:\n",
    "    for i,line in enumerate(file):\n",
    "        d[i] = re.sub(strtofind,'||',line.replace('&amp;','&')).replace('\"','').replace('\\n','').split('||')\n",
    "        \n",
    "books_df = pd.DataFrame(data=list(d.values())[1:],index=list(d.keys())[1:],columns=d[0])\n",
    "books_df.head()\n",
    "\n",
    "del d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2> Load Users Into DF </H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278853</th>\n",
       "      <td>278854</td>\n",
       "      <td>portland, oregon, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278854</th>\n",
       "      <td>278855</td>\n",
       "      <td>tacoma, washington, united kingdom</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278855</th>\n",
       "      <td>278856</td>\n",
       "      <td>brampton, ontario, canada</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278856</th>\n",
       "      <td>278857</td>\n",
       "      <td>knoxville, tennessee, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278857</th>\n",
       "      <td>278858</td>\n",
       "      <td>dublin, n/a, ireland</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        User-ID                            Location   Age\n",
       "278853   278854               portland, oregon, usa   NaN\n",
       "278854   278855  tacoma, washington, united kingdom  50.0\n",
       "278855   278856           brampton, ontario, canada   NaN\n",
       "278856   278857           knoxville, tennessee, usa   NaN\n",
       "278857   278858                dublin, n/a, ireland   NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load users file and display first 5 rows\n",
    "users_df = pd.read_csv('../data/raw/BX-Users.csv',sep=';',encoding='8859')\n",
    "users_df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Load User Ratings Of Books</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9561</th>\n",
       "      <td>2</td>\n",
       "      <td>0195153448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9562</th>\n",
       "      <td>7</td>\n",
       "      <td>034542252</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9572</th>\n",
       "      <td>8</td>\n",
       "      <td>0771025661</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9580</th>\n",
       "      <td>8</td>\n",
       "      <td>1881320189</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9579</th>\n",
       "      <td>8</td>\n",
       "      <td>1575663937</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      User-ID        ISBN  Book-Rating\n",
       "9561        2  0195153448            0\n",
       "9562        7   034542252            0\n",
       "9572        8  0771025661            0\n",
       "9580        8  1881320189            7\n",
       "9579        8  1575663937            6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df = pd.read_csv('../data/raw/BX-Book-Ratings.csv',sep=';',encoding='8859',dtype={'Book-Rating':np.int}).sort_values('User-ID')\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0375404120</td>\n",
       "      <td>266865</td>\n",
       "      <td>0</td>\n",
       "      <td>reston, virginia, usa</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>)440206529</td>\n",
       "      <td>238681</td>\n",
       "      <td>0</td>\n",
       "      <td>milford, ohio, usa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>)452273056</td>\n",
       "      <td>111422</td>\n",
       "      <td>8</td>\n",
       "      <td>avon, massachusetts, usa</td>\n",
       "      <td>59.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*0515128325</td>\n",
       "      <td>190925</td>\n",
       "      <td>0</td>\n",
       "      <td>hobe sound, florida, usa</td>\n",
       "      <td>51.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/8741060773</td>\n",
       "      <td>52796</td>\n",
       "      <td>9</td>\n",
       "      <td>sumner, iowa, usa</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ISBN  User-ID  Book-Rating                  Location   Age  \\\n",
       "0   0375404120   266865            0     reston, virginia, usa  33.0   \n",
       "1   )440206529   238681            0        milford, ohio, usa   NaN   \n",
       "2   )452273056   111422            8  avon, massachusetts, usa  59.0   \n",
       "3  *0515128325   190925            0  hobe sound, florida, usa  51.0   \n",
       "4  /8741060773    52796            9         sumner, iowa, usa   0.0   \n",
       "\n",
       "  Book-Title Book-Author Year-Of-Publication Publisher Image-URL-S  \\\n",
       "0        NaN         NaN                 NaN       NaN         NaN   \n",
       "1        NaN         NaN                 NaN       NaN         NaN   \n",
       "2        NaN         NaN                 NaN       NaN         NaN   \n",
       "3        NaN         NaN                 NaN       NaN         NaN   \n",
       "4        NaN         NaN                 NaN       NaN         NaN   \n",
       "\n",
       "  Image-URL-M Image-URL-L  \n",
       "0         NaN         NaN  \n",
       "1         NaN         NaN  \n",
       "2         NaN         NaN  \n",
       "3         NaN         NaN  \n",
       "4         NaN         NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Join user and book data to ratings data\n",
    "ratings = ratings_df.set_index('User-ID').join(users_df.set_index('User-ID')).reset_index().set_index('ISBN').join(books_df.set_index('ISBN'))\n",
    "\n",
    "## Split out users from the USA\n",
    "us_ratings = ratings[(ratings['Location'].str.lower().str.contains('usa')) | (ratings['Location'].str.lower().str.contains('states'))].reset_index()\n",
    "us_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Drop books that have only been read once. These can not be used for good recommendations</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many times a book must have been read to keep it in ratings\n",
    "min_book_read_count = 2\n",
    "\n",
    "isbn_val_counts = us_ratings['ISBN'].value_counts()\n",
    "books_to_keep = set(isbn_val_counts[isbn_val_counts>=min_book_read_count].index)\n",
    "\n",
    "filtered_us_ratings = us_ratings[us_ratings['ISBN'].isin(books_to_keep)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Split data into training and test sets</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_us_training,ratings_us_test = train_test_split(filtered_us_ratings,test_size=.20,random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Insert data into graph data structure</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "user_nodes = set(ratings_us_training['User-ID'].unique())\n",
    "book_nodes = set(ratings_us_training['ISBN'].unique())\n",
    "\n",
    "# Build the graph structure from pandas data frame\n",
    "G = nx.from_pandas_edgelist(ratings_us_training,'User-ID','ISBN',['Book-Rating'])\n",
    "\n",
    "# Compute DCS\n",
    "dcs = nx.bipartite.degree_centrality(G,user_nodes)\n",
    "\n",
    "# Add Meta Data\n",
    "for i,row in ratings_us_training.iterrows():\n",
    "    user_node = G.node[row['User-ID']]\n",
    "    book_node = G.node[row['ISBN']]\n",
    "    \n",
    "    user_node['Age'] = row['Age']\n",
    "    user_node['Location'] = row['Location']\n",
    "    user_node['bipartite'] = 'user'\n",
    "    user_node['dcs'] = dcs[row['User-ID']]\n",
    "    \n",
    "    \n",
    "    book_node['bipartite'] = 'book'\n",
    "    book_node['Book-Title'] = row['Book-Title']\n",
    "    book_node['Book-Author'] = row['Book-Author']\n",
    "    book_node['Publisher'] = row['Publisher']\n",
    "    book_node['Publication_Year'] = row['Year-Of-Publication']\n",
    "    book_node['dcs'] = dcs[row['ISBN']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create a user and book biadjacency matrix with users as rows and books as columns </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the rating as weight to add weight to explicit reviews to similarity scores\n",
    "user_arr = np.array(list(user_nodes))\n",
    "books_arr = np.array(list(book_nodes))\n",
    "user_adj_matrix = nx.bipartite.biadjacency_matrix(G,row_order=user_nodes,column_order=book_nodes,weight='Book-Rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create a user x user matrix with the cosine similarities as their intersection value</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rich.wolff\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py:730: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "# Take cosine similarities of users based on ratings they've given each book (column)\n",
    "user_sims = cosine_similarity(user_adj_matrix,dense_output=False)\n",
    "user_sims.setdiag(0)\n",
    "user_sims_coo = user_sims.tocoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collaborative_filter(selected_user,node_list,user_matrix,top_n_similarities):\n",
    "    \n",
    "    def node_similiarities(node, node_list, matrix):\n",
    "        '''Creates a numpy array of node similiarities (user or books)'''\n",
    "        indices = np.where(matrix.row == np.where(node_list==node)[0])[0]\n",
    "        matrix_sims_node = []\n",
    "        matrix_sims_score = []\n",
    "        nodes_sim = defaultdict(list)\n",
    "        for idx in indices:\n",
    "            cos_sim = (matrix.data[idx])\n",
    "            nodes_sim[cos_sim].append(node_list[matrix.col[idx]])\n",
    "        return nodes_sim\n",
    "    \n",
    "    def user_neighbor_books(selected_user, user_similarity_dict,top_n_similarities):\n",
    "        '''accepts a 2d array with users in the first column and similarities in the 2nd\n",
    "           returns top 10 books with scores'''\n",
    "        books = defaultdict(lambda: defaultdict(float))\n",
    "        for key in sorted(user_similarity_dict.keys(),reverse=True)[:top_n_similarities]:\n",
    "            for usr_lookup in user_similarity_dict[key]:\n",
    "                for bk in set(G.neighbors(usr_lookup)).difference(G.neighbors(selected_user)):\n",
    "                    book_rating = G[usr_lookup][bk]['Book-Rating']\n",
    "                    books[bk]['count'] += 1\n",
    "                    books[bk]['cosine'] += key\n",
    "                    books[bk]['rating'] += book_rating\n",
    "                    books[bk]['implicit_ratings'] += 1 if book_rating == 0 else 0\n",
    "                    books[bk]['explicit_ratings'] += 1 if book_rating > 0 else 0\n",
    "                    books[bk]['avg_cosine'] = books[bk]['cosine']/books[bk]['count']  \n",
    "                    books[bk]['avg_rating'] = books[bk]['rating']/books[bk]['count']\n",
    "                    if books[bk]['explicit_ratings'] > 0:\n",
    "                        books[bk]['avg_explicit_rating'] = books[bk]['rating']/books[bk]['explicit_ratings']\n",
    "                    if books[bk]['implicit_ratings'] > 0:\n",
    "                        books[bk]['explicit_implicit_ratio'] = books[bk]['explicit_ratings']/books[bk]['implicit_ratings']\n",
    "        \n",
    "        return books\n",
    "    \n",
    "    def books_dict_to_df(books_list):\n",
    "        books_list = [(b,\n",
    "               d['avg_rating'],\n",
    "               d['avg_explicit_rating'],        \n",
    "               d['avg_cosine'],\n",
    "               d['explicit_implicit_ratio'],\n",
    "               d['count'],\n",
    "               d['cosine'],\n",
    "               d['rating'],\n",
    "               d['implicit_ratings']) for b,d in zip(user_books_df.keys(),user_books_df.values())]\n",
    "        df_columns = ['ISBN','avg_rating','avg_explicit_rating','avg_cosine','explicit_implicit_ratio','user_count','cosines','ratings','implicit_ratings']\n",
    "        ret_df = pd.DataFrame(books_list,columns=df_columns)\n",
    "        ret_df['user'] = selected_user\n",
    "        return ret_df\n",
    "\n",
    "\n",
    "    user_sims_nodes = node_similiarities(selected_user,user_arr,user_sims_coo)\n",
    "    \n",
    "    user_books_df = user_neighbor_books(selected_user=selected_user,\n",
    "                                        user_similarity_dict=user_sims_nodes,\n",
    "                                        top_n_similarities=top_n_similarities)\n",
    "    \n",
    "    return books_dict_to_df(user_books_df).set_index(['user','ISBN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Test 1 user</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>avg_explicit_rating</th>\n",
       "      <th>avg_cosine</th>\n",
       "      <th>explicit_implicit_ratio</th>\n",
       "      <th>user_count</th>\n",
       "      <th>cosines</th>\n",
       "      <th>ratings</th>\n",
       "      <th>implicit_ratings</th>\n",
       "      <th>read</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th>ISBN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">35859</th>\n",
       "      <th>0312966970</th>\n",
       "      <td>7.375000</td>\n",
       "      <td>8.428571</td>\n",
       "      <td>0.058533</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.468267</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0312980140</th>\n",
       "      <td>6.800000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0.054018</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.270089</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0446610038</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.042775</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.213873</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0312976275</th>\n",
       "      <td>8.400000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.287520</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0439064872</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.047471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.189884</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0316569321</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.046403</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.185612</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0345465083</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.043949</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.175798</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0609804138</th>\n",
       "      <td>5.666667</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0.053363</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.160090</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0140293248</th>\n",
       "      <td>4.333333</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.056952</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.170856</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0142001740</th>\n",
       "      <td>5.666667</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0.047589</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.142766</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  avg_rating  avg_explicit_rating  avg_cosine  \\\n",
       "user  ISBN                                                      \n",
       "35859 0312966970    7.375000             8.428571    0.058533   \n",
       "      0312980140    6.800000             8.500000    0.054018   \n",
       "      0446610038    2.000000            10.000000    0.042775   \n",
       "      0312976275    8.400000             8.400000    0.057504   \n",
       "      0439064872    4.500000             9.000000    0.047471   \n",
       "      0316569321    2.000000             8.000000    0.046403   \n",
       "      0345465083    1.500000             6.000000    0.043949   \n",
       "      0609804138    5.666667             8.500000    0.053363   \n",
       "      0140293248    4.333333             6.500000    0.056952   \n",
       "      0142001740    5.666667             8.500000    0.047589   \n",
       "\n",
       "                  explicit_implicit_ratio  user_count   cosines  ratings  \\\n",
       "user  ISBN                                                                 \n",
       "35859 0312966970                 7.000000         8.0  0.468267     59.0   \n",
       "      0312980140                 4.000000         5.0  0.270089     34.0   \n",
       "      0446610038                 0.250000         5.0  0.213873     10.0   \n",
       "      0312976275                 0.000000         5.0  0.287520     42.0   \n",
       "      0439064872                 1.000000         4.0  0.189884     18.0   \n",
       "      0316569321                 0.333333         4.0  0.185612      8.0   \n",
       "      0345465083                 0.333333         4.0  0.175798      6.0   \n",
       "      0609804138                 2.000000         3.0  0.160090     17.0   \n",
       "      0140293248                 2.000000         3.0  0.170856     13.0   \n",
       "      0142001740                 2.000000         3.0  0.142766     17.0   \n",
       "\n",
       "                  implicit_ratings  read  \n",
       "user  ISBN                                \n",
       "35859 0312966970               1.0   0.0  \n",
       "      0312980140               1.0   1.0  \n",
       "      0446610038               4.0   1.0  \n",
       "      0312976275               0.0   0.0  \n",
       "      0439064872               2.0   1.0  \n",
       "      0316569321               3.0   0.0  \n",
       "      0345465083               3.0   0.0  \n",
       "      0609804138               1.0   1.0  \n",
       "      0140293248               1.0   0.0  \n",
       "      0142001740               1.0   1.0  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_user = 35859     \n",
    "\n",
    "n_recommendations = 10\n",
    "recommended_books = collaborative_filter(selected_user,user_arr,user_sims_coo,100)\n",
    "recommended_books = recommended_books.sort_values(['user_count','explicit_implicit_ratio'],ascending=False)\n",
    "recommended_books = recommended_books.head(n_recommendations)\n",
    "\n",
    "# Pull actual purchases\n",
    "sel_user_actual = ratings_us_test[ratings_us_test['User-ID']==selected_user]['ISBN'].to_frame()\n",
    "sel_user_actual['read'] = 1\n",
    "sel_user_actual['user'] = selected_user\n",
    "sel_user_actual.set_index(['user','ISBN'],inplace=True)\n",
    "\n",
    "# TOP N Recommendation based on cosines\n",
    "recommended_books.join(sel_user_actual).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Bring back scores for multiple users in test file</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_cosines = 25 \n",
    "n_recommendations = 50\n",
    "test_ratings_user_count = 50\n",
    "\n",
    "test_ratings_user_valcount = ratings_us_test['User-ID'].value_counts()\n",
    "filtered_test_ratings = test_ratings_user_valcount[test_ratings_user_valcount>test_ratings_user_count]\n",
    "users_to_test = filtered_test_ratings.index.values\n",
    "\n",
    "metrics = np.empty(len(users_to_test))\n",
    "\n",
    "group_df = []\n",
    "\n",
    "for i,sel_user in enumerate(users_to_test):\n",
    "    recommended_books = collaborative_filter(sel_user,user_arr,user_sims_coo,top_n_cosines)\n",
    "    \n",
    "    sel_user_actual = ratings_us_test[ratings_us_test['User-ID']==sel_user]['ISBN'].to_frame()\n",
    "    sel_user_actual['read'] = 1\n",
    "    sel_user_actual['user'] = sel_user\n",
    "    sel_user_actual.set_index(['user','ISBN'],inplace=True)\n",
    "    \n",
    "    group_df.append(recommended_books.sort_values(['user_count','avg_explicit_rating'],ascending=False).head(n_recommendations).join(sel_user_actual))\n",
    "group_df = pd.concat(group_df).fillna(0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df.head(20)\n",
    "X = group_df.drop(['read'],axis=1)\n",
    "y = group_df['read']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Import sklearn items</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Logistic Regression</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>20019</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>767</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0.0  1.0\n",
       "True                 \n",
       "0.0        20019   30\n",
       "1.0          767   34"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log reg model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X,y)\n",
    "\n",
    "log_reg_coefs = pd.DataFrame(lr.coef_,columns=X.columns).T.sort_values(0,ascending=False)\n",
    "\n",
    "confusion = confusion_matrix(y,lr.predict(X))\n",
    "true_notread, false_notread, false_read, true_read = confusion.ravel()\n",
    "pd.crosstab(y,lr.predict(X), rownames=['True'], colnames=['Predicted'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Predicted Read Correctly: 0.0424\n",
      "Percent Predicted Not Read Correctly: 0.9985\n"
     ]
    }
   ],
   "source": [
    "print('Percent Predicted Read Correctly: {:.4f}'.format(true_read/(true_read+false_read)))\n",
    "print('Percent Predicted Not Read Correctly: {:.4f}'.format(true_notread/(true_notread+false_notread)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forests Classifier Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>20030</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>264</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0.0  1.0\n",
       "True                 \n",
       "0.0        20030   19\n",
       "1.0          264  537"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RANDOM FOREST CLASSIFIER\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=50)\n",
    "rfc.fit(X,y)\n",
    "\n",
    "pd.DataFrame(rfc.feature_importances_,X.columns,['Feature Importances']).sort_values('Feature Importances',ascending=False)\n",
    "\n",
    "ypred = rfc.predict(X)\n",
    "confusion = confusion_matrix(y,ypred)\n",
    "true_notread, false_notread, false_read, true_read = confusion.ravel()\n",
    "\n",
    "print('Random Forests Classifier Confusion Matrix')\n",
    "pd.crosstab(y,ypred, rownames=['True'], colnames=['Predicted'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Predicted Read Correctly: 0.6629\n",
      "Percent Predicted Not Read Correctly: 0.9992\n"
     ]
    }
   ],
   "source": [
    "print('Percent Predicted Read Correctly: {:.4f}'.format(true_read/(true_read+false_read)))\n",
    "print('Percent Predicted Not Read Correctly: {:.4f}'.format(true_notread/(true_notread+false_notread)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83029722, 0.83741007, 0.87002398, 0.85083933, 0.89976019,\n",
       "       0.88872902, 0.92470024, 0.90839329, 0.93860911, 0.94193858])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rfc,X,y,cv=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'n_estimators': 10, 'n_jobs': 1}\n",
      "0.908441247002398\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators':np.linspace(10,50,2,dtype=np.int),'criterion':['gini','entropy'],'n_jobs':[1,2,3]}\n",
    "gscv = GridSearchCV(rfc,params,cv=5)\n",
    "gscv.fit(X,y)\n",
    "print(gscv.best_params_)\n",
    "print(gscv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'n_estimators': 50, 'n_jobs': 1}\n",
      "0.7954976303317536\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators':np.linspace(1,50,2,dtype=np.int),'criterion':['gini','entropy'],'n_jobs':[1,2,3]}\n",
    "gscv = GridSearchCV(rfc,params,cv=5)\n",
    "gscv.fit(X,y)\n",
    "print(gscv.best_params_)\n",
    "print(gscv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'n_estimators': 50, 'n_jobs': 1}\n",
      "0.795260663507109\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators':np.linspace(1,50,2,dtype=np.int),'criterion':['gini','entropy'],'n_jobs':[1,2,3]}\n",
    "gscv = GridSearchCV(rfc,params,cv=5)\n",
    "gscv.fit(X,y)\n",
    "print(gscv.best_params_)\n",
    "print(gscv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'n_estimators': 75, 'n_jobs': 2}\n",
      "0.7893364928909953\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators':np.linspace(25,75,2,dtype=np.int),'criterion':['gini','entropy'],'n_jobs':[1,2,3]}\n",
    "gscv = GridSearchCV(rfc,params,cv=5)\n",
    "gscv.fit(X,y)\n",
    "print(gscv.best_params_)\n",
    "print(gscv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'n_estimators': 75, 'n_jobs': 1}\n",
      "0.790521327014218\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators':np.linspace(25,75,2,dtype=np.int),'criterion':['gini','entropy'],'n_jobs':[1,2,3]}\n",
    "gscv = GridSearchCV(rfc,params,cv=5)\n",
    "gscv.fit(X,y)\n",
    "print(gscv.best_params_)\n",
    "print(gscv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = sorted(metrics)\n",
    "n = len(x)\n",
    "y = np.arange(1, n+1)/n\n",
    "\n",
    "plt.plot(x,y);\n",
    "plt.title('Median: {}'.format(np.median(metrics)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>DONT DELETE AFTER THIS. FOR BOOK SIMILARITIES</H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create a book x book matrix with cosine similarities as their intersection values</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_adj_matrix = user_adj_matrix.T\n",
    "book_sims = cosine_similarity(book_adj_matrix,dense_output=False)\n",
    "book_sims.setdiag(0)\n",
    "book_sims_coo = book_sims.tocoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bk_mtx_ind(coo_mtx):\n",
    "    '''Loop through coordinate matrix rows and store the idx location of values in a dictionary\n",
    "       dict[row].append(idx) \n",
    "       \n",
    "       This will allow for fast lookups later vs looping through a 300MM list thousands of times later\n",
    "       \n",
    "       Move complexity from O(n^2) to O(N) (iterate matrix rows once, N every lookup is O(1) in python dicts)\n",
    "    '''  \n",
    "    bk_mtx_lkup = defaultdict(list)\n",
    "    \n",
    "    for i,bk in enumerate(coo_mtx.row):\n",
    "        bk_mtx_lkup[bk].append(i)\n",
    "        \n",
    "    return bk_mtx_lkup\n",
    "\n",
    "b = dt.datetime.now()\n",
    "bk_mtx_lkup = bk_mtx_ind(coo_mtx=book_sims_coo)\n",
    "print(dt.datetime.now() - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_collab_filter(selected_user,node_list,book_matrix,book_matrix_lookup,top_n_similarities):\n",
    "    \n",
    "    def node_similiarities(nodes, node_list, matrix,book_matrix_lookup): #### O(n^2), can i reduce this?\n",
    "        '''Creates a numpy array of node similiarities (user or books)'''\n",
    "        nodes_sim = defaultdict(list)\n",
    "        \n",
    "        # find the positions of all the books read by the user\n",
    "        book_positions = np.where(np.isin(node_list,nodes))[0]\n",
    "        \n",
    "        #For each data point from node, append value book to dictionary key cosine similarity\n",
    "        for i,pos in enumerate(book_positions):\n",
    "            for idx in book_matrix_lookup[pos]:\n",
    "                bk = node_list[matrix.col[idx]]\n",
    "                if not bk in nodes:\n",
    "                    nodes_sim[matrix.data[idx]].append(bk)\n",
    "                \n",
    "        return nodes_sim\n",
    "    \n",
    "    def user_neighbor_books(book_similarity_dict, top_n_similarities,user_read_books):\n",
    "        '''accepts a 2d array with users in the first column and similarities in the 2nd\n",
    "           returns top 10 books with scores'''\n",
    "        books = defaultdict(lambda: defaultdict(float))\n",
    "        for key in sorted(book_similarity_dict.keys(),reverse=True)[:top_n_similarities]:\n",
    "            for bk in book_similarity_dict[key]:\n",
    "                if not bk in user_read_books:\n",
    "                    books[bk]['count'] += 1\n",
    "                    books[bk]['cosine'] += key\n",
    "                    books[bk]['avg_cosine'] = books[bk]['cosine']/books[bk]['count']  \n",
    "                    books[bk]['avg_rating'] = books[bk]['rating']/books[bk]['count']\n",
    "        return books\n",
    "    \n",
    "    def books_dict_to_df(books_list):\n",
    "        books_list = [(b,\n",
    "               d['avg_rating'],        \n",
    "               d['avg_cosine'],\n",
    "               d['count'],\n",
    "               d['cosine']) for b,d in zip(book_books_df.keys(),book_books_df.values())]\n",
    "        df_columns = ['book','avg_rating','avg_cosine','book_count','cosines']\n",
    "        return pd.DataFrame(books_list,columns=df_columns)\n",
    "    \n",
    "    ## return top cosine similarities books based on books user read\n",
    "    \n",
    "    ## For books user read\n",
    "        # Get books with high cosine similarities to each book\n",
    "        # count and store in dict/data frame\n",
    "\n",
    "    ### GET BOOK LIST\n",
    "    dfa = defaultdict(list)\n",
    "    user_read_books = set(G.neighbors(selected_user))\n",
    "    for x in list(user_read_books):\n",
    "        dfa[G[selected_user][x]['Book-Rating']].append(x)  \n",
    "        \n",
    "    top_5_keys = sorted(dfa.keys())[-1::]\n",
    "    top_5_rated_books = []\n",
    "    for x in top_5_keys:\n",
    "        top_5_rated_books += dfa[x]\n",
    "    \n",
    "    \n",
    "    book_sims_nodes = node_similiarities(np.array(top_5_rated_books),node_list,book_matrix,book_matrix_lookup)\n",
    "    \n",
    "    book_books_df = user_neighbor_books(book_similarity_dict=book_sims_nodes,\n",
    "                                        top_n_similarities=top_n_similarities,user_read_books=user_read_books)\n",
    "    \n",
    "    return books_dict_to_df(book_books_df).set_index('book')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3896"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(G.neighbors(selected_user)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "selected_user = 153662\n",
    "res = book_collab_filter(selected_user,books_arr,book_sims_coo,bk_mtx_lkup,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull actual purchases\n",
    "sel_user_actual = ratings_us_test[ratings_us_test['User-ID']==selected_user]['ISBN'].to_frame()\n",
    "sel_user_actual['read'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>avg_cosine</th>\n",
       "      <th>book_count</th>\n",
       "      <th>cosines</th>\n",
       "      <th>read</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0505524236</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.724476</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.448952</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0671737694</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0874062853</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0671535307</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8440629583</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0831713097</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0590414151</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569870454</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570825181</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8440632185</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895565669</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>006024240X</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0913367818</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8440643306</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0440407117</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            avg_rating  avg_cosine  book_count   cosines  read\n",
       "book                                                          \n",
       "0505524236         0.0    0.724476         2.0  1.448952   NaN\n",
       "0671737694         0.0    0.707107         2.0  1.414214   NaN\n",
       "0874062853         0.0    0.707107         2.0  1.414214   NaN\n",
       "0671535307         0.0    0.707107         2.0  1.414214   NaN\n",
       "8440629583         0.0    0.707107         2.0  1.414214   NaN\n",
       "0831713097         0.0    0.707107         2.0  1.414214   NaN\n",
       "0590414151         0.0    0.707107         2.0  1.414214   NaN\n",
       "1569870454         0.0    0.707107         2.0  1.414214   NaN\n",
       "1570825181         0.0    0.707107         2.0  1.414214   NaN\n",
       "8440632185         0.0    0.707107         2.0  1.414214   NaN\n",
       "1895565669         0.0    0.707107         2.0  1.414214   NaN\n",
       "006024240X         0.0    0.707107         2.0  1.414214   NaN\n",
       "0913367818         0.0    0.707107         2.0  1.414214   NaN\n",
       "8440643306         0.0    0.707107         2.0  1.414214   NaN\n",
       "0440407117         0.0    0.707107         2.0  1.414214   NaN"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TOP N Recommendation based on cosines\n",
    "n_recommendations = 15\n",
    "reco_test = res.sort_values(['book_count','avg_cosine'],ascending=False).head(n_recommendations).join(sel_user_actual.set_index('ISBN'))\n",
    "reco_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_n_cosines = 50 \n",
    "n_recommendations = 15\n",
    "test_ratings_user_count = 50\n",
    "\n",
    "test_ratings_user_valcount = ratings_us_test['User-ID'].value_counts()\n",
    "filtered_test_ratings = test_ratings_user_valcount[test_ratings_user_valcount>test_ratings_user_count]\n",
    "users_to_test = filtered_test_ratings.index.values\n",
    "\n",
    "metrics = np.empty(len(users_to_test))\n",
    "\n",
    "for i,sel_user in enumerate(users_to_test):\n",
    "    recommended_books = collaborative_filter(sel_user,user_arr,user_sims_coo,top_n_cosines)\n",
    "    sel_user_actual = ratings_us_test[ratings_us_test['User-ID']==sel_user]['ISBN'].to_frame()\n",
    "    sel_user_actual['read'] = 1\n",
    "    reco_test = recommended_books.sort_values(['cosines','avg_rating'],ascending=False).head(n_recommendations).join(sel_user_actual.set_index('ISBN'))\n",
    "    metrics[i] = np.sum(reco_test['read'])/n_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_book_cosines(usr):\n",
    "    read_books = list(G[usr])\n",
    "    books = defaultdict(lambda: defaultdict(float))\n",
    "    for bk in read_books:\n",
    "        book_nodes,book_scores = node_similiarities(bk,books_arr,book_sims_coo)\n",
    "        for book,score in zip(book_nodes,book_scores):\n",
    "            books[book]['cosine_total'] +=score\n",
    "            books[book]['count'] += 1\n",
    "            books[book]['avg_cosine'] = books[book]['cosine_total']/books[book]['count']\n",
    "        \n",
    "    return books\n",
    "\n",
    "book_list = user_book_cosines(selected_user)\n",
    "book_list = [(b,\n",
    "               d['cosine_total'],\n",
    "               d['count'],\n",
    "               d['avg_cosine']) for b,d in zip(book_list.keys(),book_list.values())]\n",
    "book_book_df = pd.DataFrame(book_list,columns=['book','book_book_cosine','book_book_count','book_book_avgcosine'])\n",
    "book_book_df.sort_values('book_book_count',ascending=False,inplace=True)\n",
    "book_book_df.set_index('book',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(G[selected_user])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(G.neighbors('034542252'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(G.neighbors(166409)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_scores[user_scores>np.percentile(user_scores,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "book_reco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Build books into dataframe</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_book_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = book_reco.join(book_book_df,how='outer')\n",
    "\n",
    "np.percentile(tst['avg_user_cosines'].fillna(0),99.9) #book_book_avgcosine, #avg_user_cosines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_user_actual = ratings_us_test[ratings_us_test['User-ID']==selected_user]['ISBN'].to_frame()\n",
    "sel_user_actual['read'] = 1\n",
    "tst1 = tst.join(sel_user_actual.set_index('ISBN'),how='outer')\n",
    "np.sum(tst1['read']>0)/len(tst1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tst1['book_book_avgcosine'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst1['avg_user_cosines'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df['User-ID'].value_counts()[ratings_df['User-ID'].value_counts()<3].sum()/len(ratings_df['User-ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_us_test['User-ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_reco_filtered = book_reco[book_reco['user_count'] >= 10]\n",
    "book_reco_filtered['avg_user_cosine'] = book_reco_filtered['user_cosines']/book_reco_filtered['user_count']\n",
    "top_10_books = set(book_reco_filtered.sort_values('avg_user_cosine',ascending=False).iloc[:10]['book'])\n",
    "top_10_books.intersection(set(ratings_us_test[ratings_us_test['User-ID']==selected_user].sort_values('ISBN')['ISBN']))\n",
    "#top_10_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
