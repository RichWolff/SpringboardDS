{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import re\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''#import plotly for interactive chart\n",
    "import plotly.plotly as py\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='richwolff', api_key='v0qPC120X33yPvAMDQXi')\n",
    "from plotly.graph_objs import * '''\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import defaultdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Load books into dataframe</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = defaultdict(list)\n",
    "\n",
    "strtofind = r'\";\"'\n",
    "with open('../data/raw/BX-Books.csv','r',encoding='8859') as file:\n",
    "    for i,line in enumerate(file):\n",
    "        d[i] = re.sub(strtofind,'||',line.replace('&amp;','&')).replace('\"','').replace('\\n','').split('||')\n",
    "        \n",
    "books_df = pd.DataFrame(data=list(d.values())[1:],index=list(d.keys())[1:],columns=d[0])\n",
    "del d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "      <th>origin</th>\n",
       "      <th>1st_3_publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243630</th>\n",
       "      <td>706400402X</td>\n",
       "      <td>Oriental Rugs and Carpets</td>\n",
       "      <td>Stanley Reed</td>\n",
       "      <td>0</td>\n",
       "      <td>Octopus Books</td>\n",
       "      <td>http://images.amazon.com/images/P/706400402X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/706400402X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/706400402X.0...</td>\n",
       "      <td>China</td>\n",
       "      <td>064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79353</th>\n",
       "      <td>7108009153</td>\n",
       "      <td>Zi ben zhu yi yu er shi yi shi ji</td>\n",
       "      <td>Ray Huang</td>\n",
       "      <td>1997</td>\n",
       "      <td>Jing xiao Xin hua shu dian</td>\n",
       "      <td>http://images.amazon.com/images/P/7108009153.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/7108009153.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/7108009153.0...</td>\n",
       "      <td>China</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226475</th>\n",
       "      <td>710800982X</td>\n",
       "      <td>Wan li shi wu nian (Huang Renyu zuo pin xi lie)</td>\n",
       "      <td>Ray Huang</td>\n",
       "      <td>1997</td>\n",
       "      <td>Jing xiao Xin hua shu dian</td>\n",
       "      <td>http://images.amazon.com/images/P/710800982X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/710800982X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/710800982X.0...</td>\n",
       "      <td>China</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19579</th>\n",
       "      <td>7119020412</td>\n",
       "      <td>Tales From Ancient China's Imperial Harem</td>\n",
       "      <td>Yuan Yang</td>\n",
       "      <td>1998</td>\n",
       "      <td>Foreign Languages Press</td>\n",
       "      <td>http://images.amazon.com/images/P/7119020412.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/7119020412.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/7119020412.0...</td>\n",
       "      <td>China</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125185</th>\n",
       "      <td>711900557X</td>\n",
       "      <td>The pocket interpreter, Chinese</td>\n",
       "      <td>Lydia Chen</td>\n",
       "      <td>1988</td>\n",
       "      <td>Foreign Languages Press</td>\n",
       "      <td>http://images.amazon.com/images/P/711900557X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/711900557X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/711900557X.0...</td>\n",
       "      <td>China</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISBN                                       Book-Title  \\\n",
       "243630  706400402X                        Oriental Rugs and Carpets   \n",
       "79353   7108009153                Zi ben zhu yi yu er shi yi shi ji   \n",
       "226475  710800982X  Wan li shi wu nian (Huang Renyu zuo pin xi lie)   \n",
       "19579   7119020412        Tales From Ancient China's Imperial Harem   \n",
       "125185  711900557X                  The pocket interpreter, Chinese   \n",
       "\n",
       "         Book-Author Year-Of-Publication                   Publisher  \\\n",
       "243630  Stanley Reed                   0               Octopus Books   \n",
       "79353      Ray Huang                1997  Jing xiao Xin hua shu dian   \n",
       "226475     Ray Huang                1997  Jing xiao Xin hua shu dian   \n",
       "19579      Yuan Yang                1998     Foreign Languages Press   \n",
       "125185    Lydia Chen                1988     Foreign Languages Press   \n",
       "\n",
       "                                              Image-URL-S  \\\n",
       "243630  http://images.amazon.com/images/P/706400402X.0...   \n",
       "79353   http://images.amazon.com/images/P/7108009153.0...   \n",
       "226475  http://images.amazon.com/images/P/710800982X.0...   \n",
       "19579   http://images.amazon.com/images/P/7119020412.0...   \n",
       "125185  http://images.amazon.com/images/P/711900557X.0...   \n",
       "\n",
       "                                              Image-URL-M  \\\n",
       "243630  http://images.amazon.com/images/P/706400402X.0...   \n",
       "79353   http://images.amazon.com/images/P/7108009153.0...   \n",
       "226475  http://images.amazon.com/images/P/710800982X.0...   \n",
       "19579   http://images.amazon.com/images/P/7119020412.0...   \n",
       "125185  http://images.amazon.com/images/P/711900557X.0...   \n",
       "\n",
       "                                              Image-URL-L origin  \\\n",
       "243630  http://images.amazon.com/images/P/706400402X.0...  China   \n",
       "79353   http://images.amazon.com/images/P/7108009153.0...  China   \n",
       "226475  http://images.amazon.com/images/P/710800982X.0...  China   \n",
       "19579   http://images.amazon.com/images/P/7119020412.0...  China   \n",
       "125185  http://images.amazon.com/images/P/711900557X.0...  China   \n",
       "\n",
       "       1st_3_publisher  \n",
       "243630             064  \n",
       "79353              108  \n",
       "226475             108  \n",
       "19579              119  \n",
       "125185             119  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## https://en.wikipedia.org/wiki/List_of_ISBN_identifier_groups\n",
    "def book_lan_nationality(x):\n",
    "    if x in ('0','1'):\n",
    "        return 'English'\n",
    "    elif not x in ('2','3','4','5','7'):\n",
    "        return 'Other'\n",
    "    elif x == '2':\n",
    "        return 'French'\n",
    "    elif x == '3':\n",
    "        return 'German'\n",
    "    elif x == '4':\n",
    "        return 'Japan'\n",
    "    elif x == '5': \n",
    "        return 'former USSR'\n",
    "    elif x == '7': \n",
    "        return 'China'\n",
    "    return None\n",
    "\n",
    "books_df['origin'] = books_df['ISBN'].str.slice(0,1).apply(book_lan_nationality)\n",
    "books_df['1st_3_publisher'] =books_df['ISBN'].str.slice(0,4).apply(lambda x: x[1:4] if x[0] in ('0','1','2','3','4','5','7') else 'Other')\n",
    "books_df.sort_values(['origin','1st_3_publisher']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2> Load Users Into DF </H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278853</th>\n",
       "      <td>278854</td>\n",
       "      <td>portland, oregon, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278854</th>\n",
       "      <td>278855</td>\n",
       "      <td>tacoma, washington, united kingdom</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278855</th>\n",
       "      <td>278856</td>\n",
       "      <td>brampton, ontario, canada</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278856</th>\n",
       "      <td>278857</td>\n",
       "      <td>knoxville, tennessee, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278857</th>\n",
       "      <td>278858</td>\n",
       "      <td>dublin, n/a, ireland</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        User-ID                            Location   Age\n",
       "278853   278854               portland, oregon, usa   NaN\n",
       "278854   278855  tacoma, washington, united kingdom  50.0\n",
       "278855   278856           brampton, ontario, canada   NaN\n",
       "278856   278857           knoxville, tennessee, usa   NaN\n",
       "278857   278858                dublin, n/a, ireland   NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load users file and display first 5 rows\n",
    "users_df = pd.read_csv('../data/raw/BX-Users.csv',sep=';',encoding='8859')\n",
    "users_df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>There may be similarities of books read within certain age ranges. I'll create a category of age ranges to see if we can increase the accuracy of our model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtsAAAEyCAYAAAAr0xx/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "users_df['Age'].hist(bins=50,figsize=(12,5))\n",
    "plt.xticks(np.linspace(0,100,50,dtype=np.int));\n",
    "plt.xlim(0,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age Ranges:\n",
    "<ul>\n",
    "<LI>LT 16</LI><LI>16 - 20</LI><LI>20 - 30</LI><LI>30 - 40</LI><LI>40 - 55</LI><LI>55+</LI>\n",
    "</UL>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_range(x):\n",
    "    if x < 16:\n",
    "        return 'LT 16'\n",
    "    elif x >=16 and x < 20:\n",
    "        return '16-20'\n",
    "    elif x >=20 and  x < 30:\n",
    "        return '20-30'\n",
    "    elif x >=30 and x < 40:\n",
    "        return '20-40'\n",
    "    elif x >=40 and x < 55:\n",
    "        return '40-55'\n",
    "    elif x >= 55:\n",
    "        return 'GT 55'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "users_df['age_range'] = users_df['Age'].apply(age_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Load User Ratings Of Books</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9561</th>\n",
       "      <td>2</td>\n",
       "      <td>0195153448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9562</th>\n",
       "      <td>7</td>\n",
       "      <td>034542252</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9572</th>\n",
       "      <td>8</td>\n",
       "      <td>0771025661</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9580</th>\n",
       "      <td>8</td>\n",
       "      <td>1881320189</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9579</th>\n",
       "      <td>8</td>\n",
       "      <td>1575663937</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      User-ID        ISBN  Book-Rating\n",
       "9561        2  0195153448            0\n",
       "9562        7   034542252            0\n",
       "9572        8  0771025661            0\n",
       "9580        8  1881320189            7\n",
       "9579        8  1575663937            6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df = pd.read_csv('../data/raw/BX-Book-Ratings.csv',sep=';',encoding='8859',dtype={'Book-Rating':np.int}).sort_values('User-ID')\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "      <th>age_range</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "      <th>origin</th>\n",
       "      <th>1st_3_publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0375404120</td>\n",
       "      <td>266865</td>\n",
       "      <td>0</td>\n",
       "      <td>reston, virginia, usa</td>\n",
       "      <td>33.0</td>\n",
       "      <td>20-40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>)440206529</td>\n",
       "      <td>238681</td>\n",
       "      <td>0</td>\n",
       "      <td>milford, ohio, usa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>)452273056</td>\n",
       "      <td>111422</td>\n",
       "      <td>8</td>\n",
       "      <td>avon, massachusetts, usa</td>\n",
       "      <td>59.0</td>\n",
       "      <td>GT 55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*0515128325</td>\n",
       "      <td>190925</td>\n",
       "      <td>0</td>\n",
       "      <td>hobe sound, florida, usa</td>\n",
       "      <td>51.0</td>\n",
       "      <td>40-55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/8741060773</td>\n",
       "      <td>52796</td>\n",
       "      <td>9</td>\n",
       "      <td>sumner, iowa, usa</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LT 16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ISBN  User-ID  Book-Rating                  Location   Age  \\\n",
       "0   0375404120   266865            0     reston, virginia, usa  33.0   \n",
       "1   )440206529   238681            0        milford, ohio, usa   NaN   \n",
       "2   )452273056   111422            8  avon, massachusetts, usa  59.0   \n",
       "3  *0515128325   190925            0  hobe sound, florida, usa  51.0   \n",
       "4  /8741060773    52796            9         sumner, iowa, usa   0.0   \n",
       "\n",
       "  age_range Book-Title Book-Author Year-Of-Publication Publisher Image-URL-S  \\\n",
       "0     20-40        NaN         NaN                 NaN       NaN         NaN   \n",
       "1   Unknown        NaN         NaN                 NaN       NaN         NaN   \n",
       "2     GT 55        NaN         NaN                 NaN       NaN         NaN   \n",
       "3     40-55        NaN         NaN                 NaN       NaN         NaN   \n",
       "4     LT 16        NaN         NaN                 NaN       NaN         NaN   \n",
       "\n",
       "  Image-URL-M Image-URL-L origin 1st_3_publisher  \n",
       "0         NaN         NaN    NaN             NaN  \n",
       "1         NaN         NaN    NaN             NaN  \n",
       "2         NaN         NaN    NaN             NaN  \n",
       "3         NaN         NaN    NaN             NaN  \n",
       "4         NaN         NaN    NaN             NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Join user and book data to ratings data\n",
    "ratings = ratings_df.set_index('User-ID').join(users_df.set_index('User-ID')).reset_index().set_index('ISBN').join(books_df.set_index('ISBN'))\n",
    "\n",
    "## Split out users from the USA\n",
    "us_ratings = ratings[(ratings['Location'].str.lower().str.contains('usa')) | (ratings['Location'].str.lower().str.contains('states'))].reset_index()\n",
    "us_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Drop books that have only been read once. These can not be used for good recommendations</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many times a book must have been read to keep it in ratings\n",
    "min_book_read_count = 2\n",
    "\n",
    "isbn_val_counts = us_ratings['ISBN'].value_counts()\n",
    "books_to_keep = set(isbn_val_counts[isbn_val_counts>=min_book_read_count].index)\n",
    "\n",
    "filtered_us_ratings = us_ratings[us_ratings['ISBN'].isin(books_to_keep)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Split data into training and test sets</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_us_training,ratings_us_test = train_test_split(filtered_us_ratings,test_size=.20,random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Insert data into graph data structure</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "user_nodes = set(ratings_us_training['User-ID'].unique())\n",
    "book_nodes = set(ratings_us_training['ISBN'].unique())\n",
    "\n",
    "# Build the graph structure from pandas data frame\n",
    "G = nx.from_pandas_edgelist(ratings_us_training,'User-ID','ISBN',['Book-Rating'])\n",
    "\n",
    "# Compute DCS\n",
    "dcs = nx.bipartite.degree_centrality(G,user_nodes)\n",
    "\n",
    "# Add Meta Data\n",
    "for i,row in ratings_us_training.iterrows():\n",
    "    user_node = G.node[row['User-ID']]\n",
    "    book_node = G.node[row['ISBN']]\n",
    "    \n",
    "    user_node['age_range'] = row['age_range']\n",
    "    user_node['Location'] = row['Location']\n",
    "    user_node['bipartite'] = 'user'\n",
    "    user_node['dcs'] = dcs[row['User-ID']]\n",
    "    \n",
    "    book_node['origin'] = row['origin']\n",
    "    book_node['isbn_1st_3'] = row['1st_3_publisher']\n",
    "    book_node['bipartite'] = 'book'\n",
    "    book_node['Book-Title'] = row['Book-Title']\n",
    "    book_node['Book-Author'] = row['Book-Author']\n",
    "    book_node['Publisher'] = row['Publisher']\n",
    "    book_node['Publication_Year'] = row['Year-Of-Publication']\n",
    "    book_node['dcs'] = dcs[row['ISBN']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create a user and book biadjacency matrix with users as rows and books as columns </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the rating as weight to add weight to explicit reviews to similarity scores\n",
    "user_arr = np.array(list(user_nodes))\n",
    "books_arr = np.array(list(book_nodes))\n",
    "user_adj_matrix = nx.bipartite.biadjacency_matrix(G,row_order=user_nodes,column_order=book_nodes,weight='Book-Rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create a user x user matrix with the cosine similarities as their intersection value</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rich.wolff\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py:730: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "# Take cosine similarities of users based on ratings they've given each book (column)\n",
    "user_sims = cosine_similarity(user_adj_matrix,dense_output=False)\n",
    "user_sims.setdiag(0)\n",
    "user_sims_coo = user_sims.tocoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collaborative_filter(selected_user,node_list,user_matrix,top_n_similarities):\n",
    "    \n",
    "    def node_similiarities(node, node_list, matrix):\n",
    "        '''Creates a numpy array of node similiarities (user or books)'''\n",
    "        node_agerange = G.node[node]['age_range']\n",
    "        indices = np.where(matrix.row == np.where(node_list==node)[0])[0]\n",
    "        matrix_sims_node = []\n",
    "        matrix_sims_score = []\n",
    "        nodes_sim = defaultdict(list)\n",
    "        for idx in indices:\n",
    "            neighbor = node_list[matrix.col[idx]]\n",
    "            #if G.node[neighbor]['age_range'] == node_agerange:\n",
    "            cos_sim = (matrix.data[idx])\n",
    "            nodes_sim[cos_sim].append(neighbor)\n",
    "        return nodes_sim\n",
    "    \n",
    "    def user_neighbor_books(selected_user, user_similarity_dict,top_n_similarities):\n",
    "        '''accepts a 2d array with users in the first column and similarities in the 2nd\n",
    "           returns top 10 books with scores'''\n",
    "        books = defaultdict(lambda: defaultdict(float))\n",
    "        for key in sorted(user_similarity_dict.keys(),reverse=True)[:top_n_similarities]:\n",
    "            for usr_lookup in user_similarity_dict[key]:\n",
    "                for bk in set(G.neighbors(usr_lookup)).difference(G.neighbors(selected_user)):\n",
    "                    book_rating = G[usr_lookup][bk]['Book-Rating']\n",
    "                    books[bk]['count'] += 1\n",
    "                    books[bk]['cosine'] += key\n",
    "                    books[bk]['rating'] += book_rating\n",
    "                    books[bk]['implicit_ratings'] += 1 if book_rating == 0 else 0\n",
    "                    books[bk]['explicit_ratings'] += 1 if book_rating > 0 else 0\n",
    "                    books[bk]['avg_cosine'] = books[bk]['cosine']/books[bk]['count']  \n",
    "                    books[bk]['avg_rating'] = books[bk]['rating']/books[bk]['count']\n",
    "                    if books[bk]['explicit_ratings'] > 0:\n",
    "                        books[bk]['avg_explicit_rating'] = books[bk]['rating']/books[bk]['explicit_ratings']\n",
    "                    if books[bk]['implicit_ratings'] > 0:\n",
    "                        books[bk]['explicit_implicit_ratio'] = books[bk]['explicit_ratings']/books[bk]['implicit_ratings']\n",
    "        \n",
    "        return books\n",
    "    \n",
    "    def books_dict_to_df(books_list):\n",
    "        books_list = [(b,\n",
    "               d['avg_rating'],\n",
    "               d['avg_explicit_rating'],        \n",
    "               d['avg_cosine'],\n",
    "               d['explicit_implicit_ratio'],\n",
    "               d['count'],\n",
    "               d['cosine'],\n",
    "               d['rating'],\n",
    "               d['implicit_ratings']) for b,d in zip(user_books_df.keys(),user_books_df.values())]\n",
    "        df_columns = ['ISBN','avg_rating','avg_explicit_rating','avg_cosine','explicit_implicit_ratio','user_count','cosines','ratings','implicit_ratings']\n",
    "        ret_df = pd.DataFrame(books_list,columns=df_columns)\n",
    "        ret_df['user'] = selected_user\n",
    "        return ret_df\n",
    "\n",
    "\n",
    "    user_sims_nodes = node_similiarities(selected_user,user_arr,user_sims_coo)\n",
    "    \n",
    "    user_books_df = user_neighbor_books(selected_user=selected_user,\n",
    "                                        user_similarity_dict=user_sims_nodes,\n",
    "                                        top_n_similarities=top_n_similarities)\n",
    "    \n",
    "    return books_dict_to_df(user_books_df).set_index(['user','ISBN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Test 1 user</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>avg_explicit_rating</th>\n",
       "      <th>avg_cosine</th>\n",
       "      <th>explicit_implicit_ratio</th>\n",
       "      <th>user_count</th>\n",
       "      <th>cosines</th>\n",
       "      <th>ratings</th>\n",
       "      <th>implicit_ratings</th>\n",
       "      <th>read</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th>ISBN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">278418</th>\n",
       "      <th>0515132020</th>\n",
       "      <td>6.714286</td>\n",
       "      <td>8.545455</td>\n",
       "      <td>0.061333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.858659</td>\n",
       "      <td>94.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>051513287X</th>\n",
       "      <td>6.181818</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0.050013</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.550144</td>\n",
       "      <td>68.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0515128554</th>\n",
       "      <td>5.666667</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0.051810</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310861</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0971880107</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.079278</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.475665</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0515126772</th>\n",
       "      <td>3.800000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>0.055296</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.276481</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   avg_rating  avg_explicit_rating  avg_cosine  \\\n",
       "user   ISBN                                                      \n",
       "278418 0515132020    6.714286             8.545455    0.061333   \n",
       "       051513287X    6.181818             8.500000    0.050013   \n",
       "       0515128554    5.666667             8.500000    0.051810   \n",
       "       0971880107    0.833333             5.000000    0.079278   \n",
       "       0515126772    3.800000             9.500000    0.055296   \n",
       "\n",
       "                   explicit_implicit_ratio  user_count   cosines  ratings  \\\n",
       "user   ISBN                                                                 \n",
       "278418 0515132020                 3.666667        14.0  0.858659     94.0   \n",
       "       051513287X                 2.666667        11.0  0.550144     68.0   \n",
       "       0515128554                 2.000000         6.0  0.310861     34.0   \n",
       "       0971880107                 0.200000         6.0  0.475665      5.0   \n",
       "       0515126772                 0.666667         5.0  0.276481     19.0   \n",
       "\n",
       "                   implicit_ratings  read  \n",
       "user   ISBN                                \n",
       "278418 0515132020               3.0   0.0  \n",
       "       051513287X               3.0   0.0  \n",
       "       0515128554               2.0   0.0  \n",
       "       0971880107               5.0   0.0  \n",
       "       0515126772               3.0   1.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_user = 278418     \n",
    "def collab_filter_recommendations(selected_user,n_recommendations=None):\n",
    "    recommended_books = collaborative_filter(selected_user,user_arr,user_sims_coo,100)\n",
    "    recommended_books = recommended_books.sort_values(['user_count','explicit_implicit_ratio'],ascending=False)\n",
    "    recommended_books = recommended_books.head(n_recommendations)\n",
    "\n",
    "    # Pull actual purchases\n",
    "    sel_user_actual = ratings_us_test[ratings_us_test['User-ID']==selected_user]['ISBN'].to_frame()\n",
    "    sel_user_actual['read'] = 1\n",
    "    sel_user_actual['user'] = selected_user\n",
    "    sel_user_actual.set_index(['user','ISBN'],inplace=True)\n",
    "\n",
    "    # TOP N Recommendation based on cosines\n",
    "    return recommended_books.join(sel_user_actual).fillna(0)\n",
    "\n",
    "collab_filter_recommendations(selected_user).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Bring back scores for multiple users in test file</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_cosines = 10\n",
    "n_recommendations = 100\n",
    "test_ratings_user_count = 20\n",
    "\n",
    "test_ratings_user_valcount = ratings_us_test['User-ID'].value_counts()\n",
    "filtered_test_ratings = test_ratings_user_valcount[test_ratings_user_valcount>test_ratings_user_count]\n",
    "users_to_test = filtered_test_ratings.index.values\n",
    "\n",
    "metrics = np.empty(len(users_to_test))\n",
    "\n",
    "group_df = []\n",
    "\n",
    "for i,sel_user in enumerate(users_to_test):\n",
    "    group_df.append(collab_filter_recommendations(sel_user))\n",
    "    \n",
    "group_df = pd.concat(group_df).fillna(0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2527786, 8)\n"
     ]
    }
   ],
   "source": [
    "group_df.head(20)\n",
    "X = group_df.drop(['read'],axis=1)\n",
    "y = group_df['read']\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Import sklearn items</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Logistic Regression</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>2514185</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>13360</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      0.0  1.0\n",
       "True                   \n",
       "0.0        2514185  164\n",
       "1.0          13360   77"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log reg model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X,y)\n",
    "\n",
    "log_reg_coefs = pd.DataFrame(lr.coef_,columns=X.columns).T.sort_values(0,ascending=False)\n",
    "\n",
    "confusion = confusion_matrix(y,lr.predict(X))\n",
    "true_notread, false_notread, false_read, true_read = confusion.ravel()\n",
    "pd.crosstab(y,lr.predict(X), rownames=['True'], colnames=['Predicted'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Predicted Read Correctly: 0.0057\n",
      "Percent Predicted Not Read Correctly: 0.9999\n"
     ]
    }
   ],
   "source": [
    "print('Percent Predicted Read Correctly: {:.4f}'.format(true_read/(true_read+false_read)))\n",
    "print('Percent Predicted Not Read Correctly: {:.4f}'.format(true_notread/(true_notread+false_notread)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(estimator,X,y):\n",
    "    '''Scoring function that returns % true predicitons that a user read the book'''\n",
    "    confusion = confusion_matrix(y,estimator.predict(X))\n",
    "    true_notread, false_notread, false_read, true_read = confusion.ravel()\n",
    "    return true_read/(true_read+false_read)\n",
    "\n",
    "#Logistic Regression\n",
    "params = {'C':np.linspace(1,100,100,dtype=np.int),'tol':np.linspace(.0001,1,100)}\n",
    "\n",
    "lrgrid = RandomizedSearchCV(lr,param_distributions=params,n_iter=5,n_jobs=-1,scoring=scoring)\n",
    "lrgrid.fit(X,y)\n",
    "\n",
    "best_c = lrgrid.best_params_['C']\n",
    "best_tol = lrgrid.best_params_['tol']\n",
    "print('Log Reg Grid Search')\n",
    "print('Best log reg grid search score: {:.4f}'.format(lrgrid.best_score_))\n",
    "print('Best C: {} - Best tol: {}'.format(best_c,best_tol),end='\\n\\n')\n",
    "\n",
    "lr = LogisticRegression(C=best_c, tol=best_tol)\n",
    "lr.fit(X,y)\n",
    "\n",
    "ypred = lr.predict(X)\n",
    "confusion = confusion_matrix(y,ypred)\n",
    "true_notread, false_notread, false_read, true_read = confusion.ravel()\n",
    "\n",
    "print('Log Reg Classifier Confusion Matrix')\n",
    "print('Predicted {:.1f}% of read books as read'.format(true_read/(true_read+false_read)*100))\n",
    "print('Predicted {:.1f}% of read books as unread'.format(false_read/(true_read+false_read)*100))\n",
    "print('Predicted {:.1f}% of unread books as read'.format(false_notread/(false_notread+true_notread)*100))\n",
    "print('Predicted {:.1f}% of unread books as unread'.format(true_notread/(true_notread+false_notread)*100))\n",
    "pd.crosstab(y,ypred, rownames=['True'], colnames=['Predicted'],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Logistic regression over predicts books that are not purchased/read as not purchased/read. With our goal being to recommend the books that users would want to buy, we need to maximize that metric.</h2><br>\n",
    "<h2>Next, we'll try a random forest classifier</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST CLASSIFIER\n",
    "params = {'n_estimators':np.linspace(1,100,5,dtype=np.int)}\n",
    "rfc = RandomForestClassifier()\n",
    "rfcgrid = GridSearchCV(rfc,params,scoring=scoring,cv=5,n_jobs=-1)\n",
    "rfcgrid.fit(X,y)\n",
    "\n",
    "best__n_estimators = rfcgrid.best_params_['n_estimators']\n",
    "best__criterion = rfcgrid.best_params_['criterion']\n",
    "best__n_jobs = rfcgrid.best_params_['n_jobs']\n",
    "print('Random Forests Grid Search')\n",
    "\n",
    "print('Best Random Forests grid search score: {:.4f}'.format(rfcgrid.best_score_))\n",
    "print('Best n_estimators: {:.4f} - Best Criterion: {} - Best n_jobs: {:.4f}'.format(best__n_estimators,\n",
    "                                                                                        best__criterion,\n",
    "                                                                                        best__n_jobs),end='\\n\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forests Classifier Confusion Matrix\n",
      "Predicted 35.9% of read books as read\n",
      "Predicted 64.1% of read books as unread\n",
      "Predicted 0.0% of unread books as read\n",
      "Predicted 100.0% of unread books as unread\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>2514147</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>8613</td>\n",
       "      <td>4824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      0.0   1.0\n",
       "True                    \n",
       "0.0        2514147   202\n",
       "1.0           8613  4824"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=25,criterion='gini',n_jobs=-1)\n",
    "rfc.fit(X,y)\n",
    "\n",
    "ypred = rfc.predict(X)\n",
    "confusion = confusion_matrix(y,ypred)\n",
    "true_notread, false_notread, false_read, true_read = confusion.ravel()\n",
    "\n",
    "print('Random Forests Classifier Confusion Matrix')\n",
    "print('Predicted {:.1f}% of read books as read'.format(true_read/(true_read+false_read)*100))\n",
    "print('Predicted {:.1f}% of read books as unread'.format(false_read/(true_read+false_read)*100))\n",
    "print('Predicted {:.1f}% of unread books as read'.format(false_notread/(false_notread+true_notread)*100))\n",
    "print('Predicted {:.1f}% of unread books as unread'.format(true_notread/(true_notread+false_notread)*100))\n",
    "pd.crosstab(y,ypred, rownames=['True'], colnames=['Predicted'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importancs\n",
      "\n",
      "cosines                    0.463300\n",
      "avg_cosine                 0.460837\n",
      "ratings                    0.019563\n",
      "avg_rating                 0.017357\n",
      "avg_explicit_rating        0.015863\n",
      "user_count                 0.010036\n",
      "explicit_implicit_ratio    0.008258\n",
      "implicit_ratings           0.004787\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Feature Importancs\\n')\n",
    "print(pd.Series(rfc.feature_importances_,X.columns).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(estimator,X,y):\n",
    "    '''Scoring function that returns % true predicitons that a user read the book'''\n",
    "    confusion = confusion_matrix(y,estimator.predict(X))\n",
    "    true_notread, false_notread, false_read, true_read = confusion.ravel()\n",
    "    return true_read/(true_read+false_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0639881 , 0.00669643, 0.00669643, 0.01041667, 0.00818452,\n",
       "       0.00967262, 0.00892857, 0.01563663, 0.01042442, 0.01191363])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rfc,X,y,cv=10,scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_user = 278418\n",
    "user_recommendations = collab_filter_recommendations(selected_user)\n",
    "X = user_recommendations.drop(['read'],axis=1)\n",
    "y = user_recommendations['read']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35859     1005\n",
       "153662     968\n",
       "198711     923\n",
       "98391      760\n",
       "76352      615\n",
       "278418     585\n",
       "16795      510\n",
       "110973     483\n",
       "235105     465\n",
       "230522     453\n",
       "Name: User-ID, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_us_test['User-ID'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>avg_explicit_rating</th>\n",
       "      <th>avg_cosine</th>\n",
       "      <th>explicit_implicit_ratio</th>\n",
       "      <th>user_count</th>\n",
       "      <th>cosines</th>\n",
       "      <th>ratings</th>\n",
       "      <th>implicit_ratings</th>\n",
       "      <th>read</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th>ISBN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"61\" valign=\"top\">278418</th>\n",
       "      <th>0515132020</th>\n",
       "      <td>6.714286</td>\n",
       "      <td>8.545455</td>\n",
       "      <td>0.061333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.858659</td>\n",
       "      <td>94.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>051513287X</th>\n",
       "      <td>6.181818</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0.050013</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.550144</td>\n",
       "      <td>68.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0971880107</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.079278</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.475665</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0515128554</th>\n",
       "      <td>5.666667</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0.051810</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310861</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0671527215</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.306699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0515126772</th>\n",
       "      <td>3.800000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>0.055296</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.276481</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0345339703</th>\n",
       "      <td>3.333333</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.086608</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.259823</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0515124214</th>\n",
       "      <td>3.250000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.056853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.227414</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573225789</th>\n",
       "      <td>2.666667</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.066389</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.199166</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0449221482</th>\n",
       "      <td>4.750000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>0.049471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.197886</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0440221471</th>\n",
       "      <td>2.333333</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.064923</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.194770</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0515120871</th>\n",
       "      <td>5.666667</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0.064510</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.193530</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0440224624</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.189962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0590738887</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.188439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0345391802</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.180140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0345441036</th>\n",
       "      <td>5.333333</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.059752</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.179255</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0345378490</th>\n",
       "      <td>2.333333</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.058407</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.175220</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0446608815</th>\n",
       "      <td>2.333333</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.057871</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.173613</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0446604275</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.169155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0786881852</th>\n",
       "      <td>1.666667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.055504</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.166512</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0553572997</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.083113</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.166226</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0872168255</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.162406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0345285859</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.162406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0440150167</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.162406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0375707972</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.162406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0804102988</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.162406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0743436210</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.081096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.162193</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0446606189</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.079299</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.158598</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0380703882</th>\n",
       "      <td>2.333333</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.052799</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.158397</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0312990456</th>\n",
       "      <td>1.666667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.052103</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.156308</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0590332163</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575666871</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0446364150</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0912656735</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0515118559</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0061044547</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0821773860</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0804108560</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0373223404</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>038529932X</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0373030460</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551668084</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0380719975</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0380717018</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0449212750</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0446604801</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0451166884</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575663988</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0451204115</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0671867113</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>037364003X</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0553580558</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0373240643</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0394517644</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0373115741</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0373032943</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565970799</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0515110973</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0061056014</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0373707681</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2475 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   avg_rating  avg_explicit_rating  avg_cosine  \\\n",
       "user   ISBN                                                      \n",
       "278418 0515132020    6.714286             8.545455    0.061333   \n",
       "       051513287X    6.181818             8.500000    0.050013   \n",
       "       0971880107    0.833333             5.000000    0.079278   \n",
       "       0515128554    5.666667             8.500000    0.051810   \n",
       "       0671527215    0.000000             0.000000    0.076675   \n",
       "       0515126772    3.800000             9.500000    0.055296   \n",
       "       0345339703    3.333333            10.000000    0.086608   \n",
       "       0515124214    3.250000             6.500000    0.056853   \n",
       "       1573225789    2.666667             8.000000    0.066389   \n",
       "       0449221482    4.750000             9.500000    0.049471   \n",
       "       0440221471    2.333333             7.000000    0.064923   \n",
       "       0515120871    5.666667             8.500000    0.064510   \n",
       "       0440224624    0.000000             0.000000    0.047491   \n",
       "       0590738887    0.000000             0.000000    0.094220   \n",
       "       0345391802    0.000000             0.000000    0.090070   \n",
       "       0345441036    5.333333             8.000000    0.059752   \n",
       "       0345378490    2.333333             7.000000    0.058407   \n",
       "       0446608815    2.333333             7.000000    0.057871   \n",
       "       0446604275    0.000000             0.000000    0.056385   \n",
       "       0786881852    1.666667             5.000000    0.055504   \n",
       "       0553572997    4.000000             8.000000    0.083113   \n",
       "       0872168255    0.000000             0.000000    0.162406   \n",
       "       0345285859    0.000000             0.000000    0.162406   \n",
       "       0440150167    0.000000             0.000000    0.162406   \n",
       "       0375707972    0.000000             0.000000    0.162406   \n",
       "       0804102988    0.000000             0.000000    0.162406   \n",
       "       0743436210    5.000000            10.000000    0.081096   \n",
       "       0446606189    3.000000             6.000000    0.079299   \n",
       "       0380703882    2.333333             7.000000    0.052799   \n",
       "       0312990456    1.666667             5.000000    0.052103   \n",
       "...                       ...                  ...         ...   \n",
       "       0590332163    0.000000             0.000000    0.033581   \n",
       "       1575666871    0.000000             0.000000    0.033581   \n",
       "       0446364150    7.000000             7.000000    0.033581   \n",
       "       0912656735    6.000000             6.000000    0.033581   \n",
       "       0515118559    0.000000             0.000000    0.033581   \n",
       "       0061044547    7.000000             7.000000    0.033581   \n",
       "       0821773860    0.000000             0.000000    0.033581   \n",
       "       0804108560    0.000000             0.000000    0.033581   \n",
       "       0373223404    0.000000             0.000000    0.033581   \n",
       "       038529932X    8.000000             8.000000    0.033581   \n",
       "       0373030460    0.000000             0.000000    0.033581   \n",
       "       1551668084    9.000000             9.000000    0.033581   \n",
       "       0380719975    0.000000             0.000000    0.033581   \n",
       "       0380717018    7.000000             7.000000    0.033581   \n",
       "       0449212750    8.000000             8.000000    0.033581   \n",
       "       0446604801    9.000000             9.000000    0.033581   \n",
       "       0451166884    9.000000             9.000000    0.033581   \n",
       "       1575663988    0.000000             0.000000    0.033581   \n",
       "       0451204115    9.000000             9.000000    0.033581   \n",
       "       0671867113    3.000000             3.000000    0.033581   \n",
       "       037364003X    0.000000             0.000000    0.033581   \n",
       "       0553580558    5.000000             5.000000    0.033581   \n",
       "       0373240643    0.000000             0.000000    0.033581   \n",
       "       0394517644    8.000000             8.000000    0.033581   \n",
       "       0373115741    0.000000             0.000000    0.033581   \n",
       "       0373032943    0.000000             0.000000    0.033581   \n",
       "       1565970799    0.000000             0.000000    0.033581   \n",
       "       0515110973    8.000000             8.000000    0.033581   \n",
       "       0061056014    3.000000             3.000000    0.033581   \n",
       "       0373707681    0.000000             0.000000    0.033581   \n",
       "\n",
       "                   explicit_implicit_ratio  user_count   cosines  ratings  \\\n",
       "user   ISBN                                                                 \n",
       "278418 0515132020                 3.666667        14.0  0.858659     94.0   \n",
       "       051513287X                 2.666667        11.0  0.550144     68.0   \n",
       "       0971880107                 0.200000         6.0  0.475665      5.0   \n",
       "       0515128554                 2.000000         6.0  0.310861     34.0   \n",
       "       0671527215                 0.000000         4.0  0.306699      0.0   \n",
       "       0515126772                 0.666667         5.0  0.276481     19.0   \n",
       "       0345339703                 0.500000         3.0  0.259823     10.0   \n",
       "       0515124214                 1.000000         4.0  0.227414     13.0   \n",
       "       1573225789                 0.500000         3.0  0.199166      8.0   \n",
       "       0449221482                 1.000000         4.0  0.197886     19.0   \n",
       "       0440221471                 0.500000         3.0  0.194770      7.0   \n",
       "       0515120871                 2.000000         3.0  0.193530     17.0   \n",
       "       0440224624                 0.000000         4.0  0.189962      0.0   \n",
       "       0590738887                 0.000000         2.0  0.188439      0.0   \n",
       "       0345391802                 0.000000         2.0  0.180140      0.0   \n",
       "       0345441036                 2.000000         3.0  0.179255     16.0   \n",
       "       0345378490                 0.500000         3.0  0.175220      7.0   \n",
       "       0446608815                 0.500000         3.0  0.173613      7.0   \n",
       "       0446604275                 0.000000         3.0  0.169155      0.0   \n",
       "       0786881852                 0.500000         3.0  0.166512      5.0   \n",
       "       0553572997                 1.000000         2.0  0.166226      8.0   \n",
       "       0872168255                 0.000000         1.0  0.162406      0.0   \n",
       "       0345285859                 0.000000         1.0  0.162406      0.0   \n",
       "       0440150167                 0.000000         1.0  0.162406      0.0   \n",
       "       0375707972                 0.000000         1.0  0.162406      0.0   \n",
       "       0804102988                 0.000000         1.0  0.162406      0.0   \n",
       "       0743436210                 1.000000         2.0  0.162193     10.0   \n",
       "       0446606189                 1.000000         2.0  0.158598      6.0   \n",
       "       0380703882                 0.500000         3.0  0.158397      7.0   \n",
       "       0312990456                 0.500000         3.0  0.156308      5.0   \n",
       "...                                    ...         ...       ...      ...   \n",
       "       0590332163                 0.000000         1.0  0.033581      0.0   \n",
       "       1575666871                 0.000000         1.0  0.033581      0.0   \n",
       "       0446364150                 0.000000         1.0  0.033581      7.0   \n",
       "       0912656735                 0.000000         1.0  0.033581      6.0   \n",
       "       0515118559                 0.000000         1.0  0.033581      0.0   \n",
       "       0061044547                 0.000000         1.0  0.033581      7.0   \n",
       "       0821773860                 0.000000         1.0  0.033581      0.0   \n",
       "       0804108560                 0.000000         1.0  0.033581      0.0   \n",
       "       0373223404                 0.000000         1.0  0.033581      0.0   \n",
       "       038529932X                 0.000000         1.0  0.033581      8.0   \n",
       "       0373030460                 0.000000         1.0  0.033581      0.0   \n",
       "       1551668084                 0.000000         1.0  0.033581      9.0   \n",
       "       0380719975                 0.000000         1.0  0.033581      0.0   \n",
       "       0380717018                 0.000000         1.0  0.033581      7.0   \n",
       "       0449212750                 0.000000         1.0  0.033581      8.0   \n",
       "       0446604801                 0.000000         1.0  0.033581      9.0   \n",
       "       0451166884                 0.000000         1.0  0.033581      9.0   \n",
       "       1575663988                 0.000000         1.0  0.033581      0.0   \n",
       "       0451204115                 0.000000         1.0  0.033581      9.0   \n",
       "       0671867113                 0.000000         1.0  0.033581      3.0   \n",
       "       037364003X                 0.000000         1.0  0.033581      0.0   \n",
       "       0553580558                 0.000000         1.0  0.033581      5.0   \n",
       "       0373240643                 0.000000         1.0  0.033581      0.0   \n",
       "       0394517644                 0.000000         1.0  0.033581      8.0   \n",
       "       0373115741                 0.000000         1.0  0.033581      0.0   \n",
       "       0373032943                 0.000000         1.0  0.033581      0.0   \n",
       "       1565970799                 0.000000         1.0  0.033581      0.0   \n",
       "       0515110973                 0.000000         1.0  0.033581      8.0   \n",
       "       0061056014                 0.000000         1.0  0.033581      3.0   \n",
       "       0373707681                 0.000000         1.0  0.033581      0.0   \n",
       "\n",
       "                   implicit_ratings  read  predicted  \n",
       "user   ISBN                                           \n",
       "278418 0515132020               3.0   0.0        0.0  \n",
       "       051513287X               3.0   0.0        0.0  \n",
       "       0971880107               5.0   0.0        0.0  \n",
       "       0515128554               2.0   0.0        0.0  \n",
       "       0671527215               4.0   0.0        0.0  \n",
       "       0515126772               3.0   1.0        1.0  \n",
       "       0345339703               2.0   0.0        0.0  \n",
       "       0515124214               2.0   0.0        0.0  \n",
       "       1573225789               2.0   0.0        0.0  \n",
       "       0449221482               2.0   0.0        0.0  \n",
       "       0440221471               2.0   0.0        0.0  \n",
       "       0515120871               1.0   0.0        0.0  \n",
       "       0440224624               4.0   0.0        0.0  \n",
       "       0590738887               2.0   0.0        0.0  \n",
       "       0345391802               2.0   0.0        0.0  \n",
       "       0345441036               1.0   0.0        0.0  \n",
       "       0345378490               2.0   0.0        0.0  \n",
       "       0446608815               2.0   0.0        0.0  \n",
       "       0446604275               3.0   1.0        0.0  \n",
       "       0786881852               2.0   0.0        0.0  \n",
       "       0553572997               1.0   0.0        0.0  \n",
       "       0872168255               1.0   0.0        0.0  \n",
       "       0345285859               1.0   0.0        0.0  \n",
       "       0440150167               1.0   0.0        0.0  \n",
       "       0375707972               1.0   0.0        0.0  \n",
       "       0804102988               1.0   0.0        0.0  \n",
       "       0743436210               1.0   0.0        0.0  \n",
       "       0446606189               1.0   0.0        0.0  \n",
       "       0380703882               2.0   0.0        0.0  \n",
       "       0312990456               2.0   0.0        0.0  \n",
       "...                             ...   ...        ...  \n",
       "       0590332163               1.0   0.0        0.0  \n",
       "       1575666871               1.0   0.0        0.0  \n",
       "       0446364150               0.0   0.0        0.0  \n",
       "       0912656735               0.0   0.0        0.0  \n",
       "       0515118559               1.0   0.0        0.0  \n",
       "       0061044547               0.0   0.0        0.0  \n",
       "       0821773860               1.0   0.0        0.0  \n",
       "       0804108560               1.0   0.0        0.0  \n",
       "       0373223404               1.0   0.0        0.0  \n",
       "       038529932X               0.0   0.0        0.0  \n",
       "       0373030460               1.0   0.0        0.0  \n",
       "       1551668084               0.0   0.0        0.0  \n",
       "       0380719975               1.0   0.0        0.0  \n",
       "       0380717018               0.0   0.0        0.0  \n",
       "       0449212750               0.0   0.0        0.0  \n",
       "       0446604801               0.0   0.0        0.0  \n",
       "       0451166884               0.0   0.0        0.0  \n",
       "       1575663988               1.0   0.0        0.0  \n",
       "       0451204115               0.0   0.0        0.0  \n",
       "       0671867113               0.0   1.0        0.0  \n",
       "       037364003X               1.0   0.0        0.0  \n",
       "       0553580558               0.0   0.0        0.0  \n",
       "       0373240643               1.0   0.0        0.0  \n",
       "       0394517644               0.0   0.0        0.0  \n",
       "       0373115741               1.0   0.0        0.0  \n",
       "       0373032943               1.0   0.0        0.0  \n",
       "       1565970799               1.0   0.0        0.0  \n",
       "       0515110973               0.0   0.0        0.0  \n",
       "       0061056014               0.0   0.0        0.0  \n",
       "       0373707681               1.0   0.0        0.0  \n",
       "\n",
       "[2475 rows x 10 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_recommendations['predicted'] = rfc.predict(X)\n",
    "user_recommendations.sort_values('cosines',ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = sorted(metrics)\n",
    "n = len(x)\n",
    "y = np.arange(1, n+1)/n\n",
    "\n",
    "plt.plot(x,y);\n",
    "plt.title('Median: {}'.format(np.median(metrics)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>DONT DELETE AFTER THIS. FOR BOOK SIMILARITIES</H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create a book x book matrix with cosine similarities as their intersection values</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book_adj_matrix = user_adj_matrix.T\n",
    "book_sims = cosine_similarity(book_adj_matrix,dense_output=False)\n",
    "book_sims.setdiag(0)\n",
    "book_sims_coo = book_sims.tocoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bk_mtx_ind(coo_mtx):\n",
    "    '''Loop through coordinate matrix rows and store the idx location of values in a dictionary\n",
    "       dict[row].append(idx) \n",
    "       \n",
    "       This will allow for fast lookups later vs looping through a 300MM list thousands of times later\n",
    "       \n",
    "       Move complexity from O(n^2) to O(N) (iterate matrix rows once, N every lookup is O(1) in python dicts)\n",
    "    '''  \n",
    "    bk_mtx_lkup = defaultdict(list)\n",
    "    \n",
    "    for i,bk in enumerate(coo_mtx.row):\n",
    "        bk_mtx_lkup[bk].append(i)\n",
    "        \n",
    "    return bk_mtx_lkup\n",
    "\n",
    "b = dt.datetime.now()\n",
    "bk_mtx_lkup = bk_mtx_ind(coo_mtx=book_sims_coo)\n",
    "print(dt.datetime.now() - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def book_collab_filter(selected_user,node_list,book_matrix,book_matrix_lookup,top_n_similarities):\n",
    "    \n",
    "    def node_similiarities(nodes, node_list, matrix,book_matrix_lookup): #### O(n^2), can i reduce this?\n",
    "        '''Creates a numpy array of node similiarities (user or books)'''\n",
    "        nodes_sim = defaultdict(list)\n",
    "        \n",
    "        # find the positions of all the books read by the user\n",
    "        book_positions = np.where(np.isin(node_list,nodes))[0]\n",
    "        \n",
    "        #For each data point from node, append value book to dictionary key cosine similarity\n",
    "        for i,pos in enumerate(book_positions):\n",
    "            for idx in book_matrix_lookup[pos]:\n",
    "                bk = node_list[matrix.col[idx]]\n",
    "                if not bk in nodes:\n",
    "                    nodes_sim[matrix.data[idx]].append(bk)\n",
    "                \n",
    "        return nodes_sim\n",
    "    \n",
    "    def user_neighbor_books(book_similarity_dict, top_n_similarities,user_read_books):\n",
    "        '''accepts a 2d array with users in the first column and similarities in the 2nd\n",
    "           returns top 10 books with scores'''\n",
    "        books = defaultdict(lambda: defaultdict(float))\n",
    "        for key in sorted(book_similarity_dict.keys(),reverse=True)[:top_n_similarities]:\n",
    "            for bk in book_similarity_dict[key]:\n",
    "                if not bk in user_read_books:\n",
    "                    books[bk]['count'] += 1\n",
    "                    books[bk]['cosine'] += key\n",
    "                    books[bk]['avg_cosine'] = books[bk]['cosine']/books[bk]['count']  \n",
    "                    books[bk]['avg_rating'] = books[bk]['rating']/books[bk]['count']\n",
    "        return books\n",
    "    \n",
    "    def books_dict_to_df(books_list):\n",
    "        books_list = [(b,\n",
    "               d['avg_rating'],        \n",
    "               d['avg_cosine'],\n",
    "               d['count'],\n",
    "               d['cosine']) for b,d in zip(book_books_df.keys(),book_books_df.values())]\n",
    "        df_columns = ['book','avg_rating','avg_cosine','book_count','cosines']\n",
    "        return pd.DataFrame(books_list,columns=df_columns)\n",
    "    \n",
    "    ## return top cosine similarities books based on books user read\n",
    "    \n",
    "    ## For books user read\n",
    "        # Get books with high cosine similarities to each book\n",
    "        # count and store in dict/data frame\n",
    "\n",
    "    ### GET BOOK LIST\n",
    "    dfa = defaultdict(list)\n",
    "    user_read_books = set(G.neighbors(selected_user))\n",
    "    for x in list(user_read_books):\n",
    "        dfa[G[selected_user][x]['Book-Rating']].append(x)  \n",
    "        \n",
    "    top_5_keys = sorted(dfa.keys())[-1::]\n",
    "    top_5_rated_books = []\n",
    "    for x in top_5_keys:\n",
    "        top_5_rated_books += dfa[x]\n",
    "    \n",
    "    \n",
    "    book_sims_nodes = node_similiarities(np.array(top_5_rated_books),node_list,book_matrix,book_matrix_lookup)\n",
    "    \n",
    "    book_books_df = user_neighbor_books(book_similarity_dict=book_sims_nodes,\n",
    "                                        top_n_similarities=top_n_similarities,user_read_books=user_read_books)\n",
    "    \n",
    "    return books_dict_to_df(book_books_df).set_index('book')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3896"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(G.neighbors(selected_user)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "selected_user = 153662\n",
    "res = book_collab_filter(selected_user,books_arr,book_sims_coo,bk_mtx_lkup,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pull actual purchases\n",
    "sel_user_actual = ratings_us_test[ratings_us_test['User-ID']==selected_user]['ISBN'].to_frame()\n",
    "sel_user_actual['read'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>avg_cosine</th>\n",
       "      <th>book_count</th>\n",
       "      <th>cosines</th>\n",
       "      <th>read</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0505524236</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.724476</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.448952</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0671737694</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0874062853</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0671535307</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8440629583</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0831713097</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0590414151</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569870454</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570825181</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8440632185</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895565669</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>006024240X</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0913367818</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8440643306</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0440407117</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            avg_rating  avg_cosine  book_count   cosines  read\n",
       "book                                                          \n",
       "0505524236         0.0    0.724476         2.0  1.448952   NaN\n",
       "0671737694         0.0    0.707107         2.0  1.414214   NaN\n",
       "0874062853         0.0    0.707107         2.0  1.414214   NaN\n",
       "0671535307         0.0    0.707107         2.0  1.414214   NaN\n",
       "8440629583         0.0    0.707107         2.0  1.414214   NaN\n",
       "0831713097         0.0    0.707107         2.0  1.414214   NaN\n",
       "0590414151         0.0    0.707107         2.0  1.414214   NaN\n",
       "1569870454         0.0    0.707107         2.0  1.414214   NaN\n",
       "1570825181         0.0    0.707107         2.0  1.414214   NaN\n",
       "8440632185         0.0    0.707107         2.0  1.414214   NaN\n",
       "1895565669         0.0    0.707107         2.0  1.414214   NaN\n",
       "006024240X         0.0    0.707107         2.0  1.414214   NaN\n",
       "0913367818         0.0    0.707107         2.0  1.414214   NaN\n",
       "8440643306         0.0    0.707107         2.0  1.414214   NaN\n",
       "0440407117         0.0    0.707107         2.0  1.414214   NaN"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TOP N Recommendation based on cosines\n",
    "n_recommendations = 15\n",
    "reco_test = res.sort_values(['book_count','avg_cosine'],ascending=False).head(n_recommendations).join(sel_user_actual.set_index('ISBN'))\n",
    "reco_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_n_cosines = 50 \n",
    "n_recommendations = 15\n",
    "test_ratings_user_count = 50\n",
    "\n",
    "test_ratings_user_valcount = ratings_us_test['User-ID'].value_counts()\n",
    "filtered_test_ratings = test_ratings_user_valcount[test_ratings_user_valcount>test_ratings_user_count]\n",
    "users_to_test = filtered_test_ratings.index.values\n",
    "\n",
    "metrics = np.empty(len(users_to_test))\n",
    "\n",
    "for i,sel_user in enumerate(users_to_test):\n",
    "    recommended_books = collaborative_filter(sel_user,user_arr,user_sims_coo,top_n_cosines)\n",
    "    sel_user_actual = ratings_us_test[ratings_us_test['User-ID']==sel_user]['ISBN'].to_frame()\n",
    "    sel_user_actual['read'] = 1\n",
    "    reco_test = recommended_books.sort_values(['cosines','avg_rating'],ascending=False).head(n_recommendations).join(sel_user_actual.set_index('ISBN'))\n",
    "    metrics[i] = np.sum(reco_test['read'])/n_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_book_cosines(usr):\n",
    "    read_books = list(G[usr])\n",
    "    books = defaultdict(lambda: defaultdict(float))\n",
    "    for bk in read_books:\n",
    "        book_nodes,book_scores = node_similiarities(bk,books_arr,book_sims_coo)\n",
    "        for book,score in zip(book_nodes,book_scores):\n",
    "            books[book]['cosine_total'] +=score\n",
    "            books[book]['count'] += 1\n",
    "            books[book]['avg_cosine'] = books[book]['cosine_total']/books[book]['count']\n",
    "        \n",
    "    return books\n",
    "\n",
    "book_list = user_book_cosines(selected_user)\n",
    "book_list = [(b,\n",
    "               d['cosine_total'],\n",
    "               d['count'],\n",
    "               d['avg_cosine']) for b,d in zip(book_list.keys(),book_list.values())]\n",
    "book_book_df = pd.DataFrame(book_list,columns=['book','book_book_cosine','book_book_count','book_book_avgcosine'])\n",
    "book_book_df.sort_values('book_book_count',ascending=False,inplace=True)\n",
    "book_book_df.set_index('book',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(G[selected_user])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(G.neighbors('034542252'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(list(G.neighbors(166409)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_scores[user_scores>np.percentile(user_scores,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "book_reco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Build books into dataframe</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book_book_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst = book_reco.join(book_book_df,how='outer')\n",
    "\n",
    "np.percentile(tst['avg_user_cosines'].fillna(0),99.9) #book_book_avgcosine, #avg_user_cosines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sel_user_actual = ratings_us_test[ratings_us_test['User-ID']==selected_user]['ISBN'].to_frame()\n",
    "sel_user_actual['read'] = 1\n",
    "tst1 = tst.join(sel_user_actual.set_index('ISBN'),how='outer')\n",
    "np.sum(tst1['read']>0)/len(tst1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tst1['book_book_avgcosine'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst1['avg_user_cosines'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings_df['User-ID'].value_counts()[ratings_df['User-ID'].value_counts()<3].sum()/len(ratings_df['User-ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings_us_test['User-ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book_reco_filtered = book_reco[book_reco['user_count'] >= 10]\n",
    "book_reco_filtered['avg_user_cosine'] = book_reco_filtered['user_cosines']/book_reco_filtered['user_count']\n",
    "top_10_books = set(book_reco_filtered.sort_values('avg_user_cosine',ascending=False).iloc[:10]['book'])\n",
    "top_10_books.intersection(set(ratings_us_test[ratings_us_test['User-ID']==selected_user].sort_values('ISBN')['ISBN']))\n",
    "#top_10_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
