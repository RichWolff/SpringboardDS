{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Data Science Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rich.wolff\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "#data imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#data science imports\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV,train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.decomposition import NMF,PCA\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#plotting imports\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.float_format', lambda x: '%.9f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Joins and Data Frame builds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import pre cleaned data\n",
    "data = pd.read_csv('../data/cleansed/data.csv',index_col=0).set_index('uniqueid')\n",
    "locations = pd.read_csv('../data/cleansed/locations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# join locations data\n",
    "tidy_data = data.join(locations.set_index('uniqueid')[['geographiclevel','stateabbr','cityname']]).copy()\n",
    "\n",
    "# Only keep census level data\n",
    "tidy_data = tidy_data[tidy_data['geographiclevel'] == 'Census Tract']\n",
    "\n",
    "# Drop uneeded columns\n",
    "tidy_data = tidy_data.drop(['datavaluetypeid','geographiclevel','stateabbr','cityname'],axis=1).reset_index().set_index('uniqueid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>populationcount</th>\n",
       "      <th>ACCESS2</th>\n",
       "      <th>ARTHRITIS</th>\n",
       "      <th>BINGE</th>\n",
       "      <th>BPHIGH</th>\n",
       "      <th>BPMED</th>\n",
       "      <th>CANCER</th>\n",
       "      <th>CASTHMA</th>\n",
       "      <th>CHD</th>\n",
       "      <th>CHECKUP</th>\n",
       "      <th>...</th>\n",
       "      <th>KIDNEY</th>\n",
       "      <th>LPA</th>\n",
       "      <th>MAMMOUSE</th>\n",
       "      <th>MHLTH</th>\n",
       "      <th>OBESITY</th>\n",
       "      <th>PAPTEST</th>\n",
       "      <th>PHLTH</th>\n",
       "      <th>SLEEP</th>\n",
       "      <th>STROKE</th>\n",
       "      <th>TEETHLOST</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniqueid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0107000-01073000100</th>\n",
       "      <td>3042.000000000</td>\n",
       "      <td>0.239000000</td>\n",
       "      <td>0.325000000</td>\n",
       "      <td>0.101000000</td>\n",
       "      <td>0.462000000</td>\n",
       "      <td>0.800000000</td>\n",
       "      <td>0.052000000</td>\n",
       "      <td>0.127000000</td>\n",
       "      <td>0.080000000</td>\n",
       "      <td>0.763000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036000000</td>\n",
       "      <td>0.423000000</td>\n",
       "      <td>0.742000000</td>\n",
       "      <td>0.188000000</td>\n",
       "      <td>0.467000000</td>\n",
       "      <td>0.760000000</td>\n",
       "      <td>0.196000000</td>\n",
       "      <td>0.504000000</td>\n",
       "      <td>0.055000000</td>\n",
       "      <td>0.302000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0107000-01073000300</th>\n",
       "      <td>2735.000000000</td>\n",
       "      <td>0.288000000</td>\n",
       "      <td>0.313000000</td>\n",
       "      <td>0.108000000</td>\n",
       "      <td>0.456000000</td>\n",
       "      <td>0.803000000</td>\n",
       "      <td>0.046000000</td>\n",
       "      <td>0.118000000</td>\n",
       "      <td>0.082000000</td>\n",
       "      <td>0.738000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038000000</td>\n",
       "      <td>0.437000000</td>\n",
       "      <td>0.740000000</td>\n",
       "      <td>0.185000000</td>\n",
       "      <td>0.470000000</td>\n",
       "      <td>0.732000000</td>\n",
       "      <td>0.202000000</td>\n",
       "      <td>0.494000000</td>\n",
       "      <td>0.057000000</td>\n",
       "      <td>0.333000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0107000-01073000400</th>\n",
       "      <td>3338.000000000</td>\n",
       "      <td>0.261000000</td>\n",
       "      <td>0.346000000</td>\n",
       "      <td>0.095000000</td>\n",
       "      <td>0.501000000</td>\n",
       "      <td>0.820000000</td>\n",
       "      <td>0.052000000</td>\n",
       "      <td>0.130000000</td>\n",
       "      <td>0.088000000</td>\n",
       "      <td>0.775000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040000000</td>\n",
       "      <td>0.449000000</td>\n",
       "      <td>0.736000000</td>\n",
       "      <td>0.191000000</td>\n",
       "      <td>0.488000000</td>\n",
       "      <td>0.728000000</td>\n",
       "      <td>0.211000000</td>\n",
       "      <td>0.525000000</td>\n",
       "      <td>0.065000000</td>\n",
       "      <td>0.360000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0107000-01073000500</th>\n",
       "      <td>2864.000000000</td>\n",
       "      <td>0.281000000</td>\n",
       "      <td>0.378000000</td>\n",
       "      <td>0.086000000</td>\n",
       "      <td>0.543000000</td>\n",
       "      <td>0.840000000</td>\n",
       "      <td>0.058000000</td>\n",
       "      <td>0.134000000</td>\n",
       "      <td>0.108000000</td>\n",
       "      <td>0.788000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048000000</td>\n",
       "      <td>0.471000000</td>\n",
       "      <td>0.732000000</td>\n",
       "      <td>0.194000000</td>\n",
       "      <td>0.499000000</td>\n",
       "      <td>0.708000000</td>\n",
       "      <td>0.231000000</td>\n",
       "      <td>0.526000000</td>\n",
       "      <td>0.082000000</td>\n",
       "      <td>0.402000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0107000-01073000700</th>\n",
       "      <td>2577.000000000</td>\n",
       "      <td>0.318000000</td>\n",
       "      <td>0.385000000</td>\n",
       "      <td>0.074000000</td>\n",
       "      <td>0.554000000</td>\n",
       "      <td>0.833000000</td>\n",
       "      <td>0.057000000</td>\n",
       "      <td>0.143000000</td>\n",
       "      <td>0.119000000</td>\n",
       "      <td>0.787000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057000000</td>\n",
       "      <td>0.508000000</td>\n",
       "      <td>0.705000000</td>\n",
       "      <td>0.216000000</td>\n",
       "      <td>0.528000000</td>\n",
       "      <td>0.676000000</td>\n",
       "      <td>0.258000000</td>\n",
       "      <td>0.541000000</td>\n",
       "      <td>0.096000000</td>\n",
       "      <td>0.458000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     populationcount     ACCESS2   ARTHRITIS       BINGE  \\\n",
       "uniqueid                                                                   \n",
       "0107000-01073000100   3042.000000000 0.239000000 0.325000000 0.101000000   \n",
       "0107000-01073000300   2735.000000000 0.288000000 0.313000000 0.108000000   \n",
       "0107000-01073000400   3338.000000000 0.261000000 0.346000000 0.095000000   \n",
       "0107000-01073000500   2864.000000000 0.281000000 0.378000000 0.086000000   \n",
       "0107000-01073000700   2577.000000000 0.318000000 0.385000000 0.074000000   \n",
       "\n",
       "                         BPHIGH       BPMED      CANCER     CASTHMA  \\\n",
       "uniqueid                                                              \n",
       "0107000-01073000100 0.462000000 0.800000000 0.052000000 0.127000000   \n",
       "0107000-01073000300 0.456000000 0.803000000 0.046000000 0.118000000   \n",
       "0107000-01073000400 0.501000000 0.820000000 0.052000000 0.130000000   \n",
       "0107000-01073000500 0.543000000 0.840000000 0.058000000 0.134000000   \n",
       "0107000-01073000700 0.554000000 0.833000000 0.057000000 0.143000000   \n",
       "\n",
       "                            CHD     CHECKUP     ...          KIDNEY  \\\n",
       "uniqueid                                        ...                   \n",
       "0107000-01073000100 0.080000000 0.763000000     ...     0.036000000   \n",
       "0107000-01073000300 0.082000000 0.738000000     ...     0.038000000   \n",
       "0107000-01073000400 0.088000000 0.775000000     ...     0.040000000   \n",
       "0107000-01073000500 0.108000000 0.788000000     ...     0.048000000   \n",
       "0107000-01073000700 0.119000000 0.787000000     ...     0.057000000   \n",
       "\n",
       "                            LPA    MAMMOUSE       MHLTH     OBESITY  \\\n",
       "uniqueid                                                              \n",
       "0107000-01073000100 0.423000000 0.742000000 0.188000000 0.467000000   \n",
       "0107000-01073000300 0.437000000 0.740000000 0.185000000 0.470000000   \n",
       "0107000-01073000400 0.449000000 0.736000000 0.191000000 0.488000000   \n",
       "0107000-01073000500 0.471000000 0.732000000 0.194000000 0.499000000   \n",
       "0107000-01073000700 0.508000000 0.705000000 0.216000000 0.528000000   \n",
       "\n",
       "                        PAPTEST       PHLTH       SLEEP      STROKE  \\\n",
       "uniqueid                                                              \n",
       "0107000-01073000100 0.760000000 0.196000000 0.504000000 0.055000000   \n",
       "0107000-01073000300 0.732000000 0.202000000 0.494000000 0.057000000   \n",
       "0107000-01073000400 0.728000000 0.211000000 0.525000000 0.065000000   \n",
       "0107000-01073000500 0.708000000 0.231000000 0.526000000 0.082000000   \n",
       "0107000-01073000700 0.676000000 0.258000000 0.541000000 0.096000000   \n",
       "\n",
       "                      TEETHLOST  \n",
       "uniqueid                         \n",
       "0107000-01073000100 0.302000000  \n",
       "0107000-01073000300 0.333000000  \n",
       "0107000-01073000400 0.360000000  \n",
       "0107000-01073000500 0.402000000  \n",
       "0107000-01073000700 0.458000000  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data \n",
    "tidy_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2>Now that the data is in a tidy format, I'll split the data into a train and test group. The model will be built on the training data and the test data will be held out for a final general fit test</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set variables into X and y with y being the target and X being the features.\n",
    "zscore = lambda x: (x-x.mean())/x.std()\n",
    "tidy_data_scaled = tidy_data #.transform(zscore,axis=0)\n",
    "\n",
    "y = tidy_data['OBESITY']\n",
    "X = tidy_data.drop('OBESITY',axis=1)\n",
    "\n",
    "# Separate data into train test split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,test_size=.25,random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Next, we can fit all the features to our model to see if there are any features we could focus on. My goal is to bring the features down to what explains the mode</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                OBESITY   R-squared:                       0.995\n",
      "Model:                            OLS   Adj. R-squared:                  0.995\n",
      "Method:                 Least Squares   F-statistic:                 1.379e+05\n",
      "Date:                Tue, 10 Apr 2018   Prob (F-statistic):               0.00\n",
      "Time:                        09:30:07   Log-Likelihood:                 48660.\n",
      "No. Observations:               20398   AIC:                        -9.726e+04\n",
      "Df Residuals:                   20370   BIC:                        -9.704e+04\n",
      "Df Model:                          28                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "populationcount -1.259e-07   8.33e-08     -1.511      0.131   -2.89e-07    3.74e-08\n",
      "ACCESS2             0.1795      0.006     30.979      0.000       0.168       0.191\n",
      "ARTHRITIS           0.5129      0.013     39.409      0.000       0.487       0.538\n",
      "BINGE               0.2297      0.008     28.954      0.000       0.214       0.245\n",
      "BPHIGH              0.6822      0.011     62.702      0.000       0.661       0.704\n",
      "BPMED              -0.0341      0.006     -5.398      0.000      -0.046      -0.022\n",
      "CANCER             -1.1385      0.042    -27.087      0.000      -1.221      -1.056\n",
      "CASTHMA             0.5194      0.032     16.485      0.000       0.458       0.581\n",
      "CHD                -1.6995      0.059    -29.039      0.000      -1.814      -1.585\n",
      "CHECKUP            -0.2079      0.008    -27.018      0.000      -0.223      -0.193\n",
      "CHOLSCREEN         -0.1597      0.008    -20.472      0.000      -0.175      -0.144\n",
      "COLON_SCREEN       -0.1659      0.008    -21.269      0.000      -0.181      -0.151\n",
      "COPD                0.8825      0.039     22.399      0.000       0.805       0.960\n",
      "COREM               0.0844      0.007     12.280      0.000       0.071       0.098\n",
      "COREW              -0.0454      0.007     -6.664      0.000      -0.059      -0.032\n",
      "CSMOKING            0.2338      0.011     21.392      0.000       0.212       0.255\n",
      "DENTAL             -0.0311      0.007     -4.663      0.000      -0.044      -0.018\n",
      "DIABETES            0.4169      0.030     14.032      0.000       0.359       0.475\n",
      "HIGHCHOL            0.1299      0.012     11.123      0.000       0.107       0.153\n",
      "KIDNEY              2.4951      0.121     20.647      0.000       2.258       2.732\n",
      "LPA                 0.2664      0.008     32.963      0.000       0.251       0.282\n",
      "MAMMOUSE            0.1211      0.007     16.919      0.000       0.107       0.135\n",
      "MHLTH              -0.0417      0.028     -1.488      0.137      -0.097       0.013\n",
      "PAPTEST             0.3155      0.007     43.018      0.000       0.301       0.330\n",
      "PHLTH              -0.9970      0.033    -30.437      0.000      -1.061      -0.933\n",
      "SLEEP              -0.2238      0.007    -32.037      0.000      -0.237      -0.210\n",
      "STROKE             -1.3760      0.074    -18.538      0.000      -1.521      -1.231\n",
      "TEETHLOST          -0.0053      0.008     -0.664      0.507      -0.021       0.010\n",
      "==============================================================================\n",
      "Omnibus:                      765.252   Durbin-Watson:                   1.975\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1434.200\n",
      "Skew:                          -0.294   Prob(JB):                         0.00\n",
      "Kurtosis:                       4.159   Cond. No.                     3.51e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.51e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "m0 = sm.OLS(ytrain,Xtrain).fit()\n",
    "print(m0.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2> Looking at the initial results, there are 3 values with high pvalues. Populationcount, poor mental health, and having lost teeth do not add much information to this model and will be dropped </H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC Change: -0.5810\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                OBESITY   R-squared:                       0.995\n",
      "Model:                            OLS   Adj. R-squared:                  0.995\n",
      "Method:                 Least Squares   F-statistic:                 1.544e+05\n",
      "Date:                Tue, 10 Apr 2018   Prob (F-statistic):               0.00\n",
      "Time:                        09:30:08   Log-Likelihood:                 48657.\n",
      "No. Observations:               20398   AIC:                        -9.726e+04\n",
      "Df Residuals:                   20373   BIC:                        -9.707e+04\n",
      "Df Model:                          25                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "ACCESS2          0.1781      0.006     30.917      0.000       0.167       0.189\n",
      "ARTHRITIS        0.5162      0.013     40.198      0.000       0.491       0.541\n",
      "BINGE            0.2306      0.008     29.096      0.000       0.215       0.246\n",
      "BPHIGH           0.6848      0.011     63.506      0.000       0.664       0.706\n",
      "BPMED           -0.0350      0.006     -5.570      0.000      -0.047      -0.023\n",
      "CANCER          -1.1448      0.042    -27.356      0.000      -1.227      -1.063\n",
      "CASTHMA          0.4971      0.028     17.499      0.000       0.441       0.553\n",
      "CHD             -1.6940      0.058    -29.110      0.000      -1.808      -1.580\n",
      "CHECKUP         -0.2107      0.007    -28.166      0.000      -0.225      -0.196\n",
      "CHOLSCREEN      -0.1566      0.008    -20.540      0.000      -0.172      -0.142\n",
      "COLON_SCREEN    -0.1650      0.008    -21.426      0.000      -0.180      -0.150\n",
      "COPD             0.8722      0.039     22.451      0.000       0.796       0.948\n",
      "COREM            0.0820      0.007     12.289      0.000       0.069       0.095\n",
      "COREW           -0.0439      0.007     -6.486      0.000      -0.057      -0.031\n",
      "CSMOKING         0.2314      0.011     21.531      0.000       0.210       0.252\n",
      "DENTAL          -0.0290      0.006     -4.558      0.000      -0.042      -0.017\n",
      "DIABETES         0.4232      0.030     14.319      0.000       0.365       0.481\n",
      "HIGHCHOL         0.1313      0.012     11.345      0.000       0.109       0.154\n",
      "KIDNEY           2.5440      0.118     21.573      0.000       2.313       2.775\n",
      "LPA              0.2685      0.008     33.983      0.000       0.253       0.284\n",
      "MAMMOUSE         0.1181      0.007     17.048      0.000       0.105       0.132\n",
      "PAPTEST          0.3141      0.007     43.045      0.000       0.300       0.328\n",
      "PHLTH           -1.0338      0.024    -43.794      0.000      -1.080      -0.988\n",
      "SLEEP           -0.2261      0.007    -33.144      0.000      -0.239      -0.213\n",
      "STROKE          -1.3794      0.071    -19.472      0.000      -1.518      -1.241\n",
      "==============================================================================\n",
      "Omnibus:                      756.987   Durbin-Watson:                   1.975\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1408.601\n",
      "Skew:                          -0.293   Prob(JB):                    1.34e-306\n",
      "Kurtosis:                       4.146   Cond. No.                     1.64e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.64e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Drop features with higher pvalues\n",
    "drop_high_pval = np.array(['populationcount','MHLTH','TEETHLOST'])\n",
    "Xtrain_dropped = Xtrain.drop(drop_high_pval,axis=1)\n",
    "\n",
    "# Retrain model without dropped features\n",
    "m1 = sm.OLS(ytrain,Xtrain_dropped).fit()\n",
    "print('AIC Change: {0:.4f}'.format(m1.aic-m0.aic))\n",
    "print(m1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>After we dropped those three features, we actually saw an AIC drop and it is probably fair to leave them out. It's also good to note that our R^2 did not change either.</h3>\n",
    "\n",
    "<h3>Next, Ill look at the coefficients to decipher which has the most affect on the model and whether or no that makes sense (Is a population with high Obesity % that way because they have high blood pressure, or do they have high blood pressure because they're obese?</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KIDNEY</th>\n",
       "      <td>2.312893564</td>\n",
       "      <td>2.775174768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COPD</th>\n",
       "      <td>0.796059372</td>\n",
       "      <td>0.948358392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPHIGH</th>\n",
       "      <td>0.663624526</td>\n",
       "      <td>0.705894198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CASTHMA</th>\n",
       "      <td>0.441383585</td>\n",
       "      <td>0.552737343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARTHRITIS</th>\n",
       "      <td>0.491007909</td>\n",
       "      <td>0.541346620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIABETES</th>\n",
       "      <td>0.365248731</td>\n",
       "      <td>0.481102829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAPTEST</th>\n",
       "      <td>0.299767393</td>\n",
       "      <td>0.328370276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPA</th>\n",
       "      <td>0.252989648</td>\n",
       "      <td>0.283959782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSMOKING</th>\n",
       "      <td>0.210323958</td>\n",
       "      <td>0.252452294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BINGE</th>\n",
       "      <td>0.215034675</td>\n",
       "      <td>0.246098882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACCESS2</th>\n",
       "      <td>0.166763573</td>\n",
       "      <td>0.189340144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HIGHCHOL</th>\n",
       "      <td>0.108607519</td>\n",
       "      <td>0.153973927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAMMOUSE</th>\n",
       "      <td>0.104546893</td>\n",
       "      <td>0.131711119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COREM</th>\n",
       "      <td>0.068957156</td>\n",
       "      <td>0.095128395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DENTAL</th>\n",
       "      <td>-0.041528601</td>\n",
       "      <td>-0.016551533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPMED</th>\n",
       "      <td>-0.047352980</td>\n",
       "      <td>-0.022700161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COREW</th>\n",
       "      <td>-0.057143028</td>\n",
       "      <td>-0.030620363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHOLSCREEN</th>\n",
       "      <td>-0.171566985</td>\n",
       "      <td>-0.141674521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLON_SCREEN</th>\n",
       "      <td>-0.180094221</td>\n",
       "      <td>-0.149905676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHECKUP</th>\n",
       "      <td>-0.225338784</td>\n",
       "      <td>-0.196016461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLEEP</th>\n",
       "      <td>-0.239482943</td>\n",
       "      <td>-0.212739187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PHLTH</th>\n",
       "      <td>-1.080072540</td>\n",
       "      <td>-0.987533269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CANCER</th>\n",
       "      <td>-1.226799885</td>\n",
       "      <td>-1.062754092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STROKE</th>\n",
       "      <td>-1.518222865</td>\n",
       "      <td>-1.240522461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHD</th>\n",
       "      <td>-1.808064166</td>\n",
       "      <td>-1.579936603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      low         high\n",
       "KIDNEY        2.312893564  2.775174768\n",
       "COPD          0.796059372  0.948358392\n",
       "BPHIGH        0.663624526  0.705894198\n",
       "CASTHMA       0.441383585  0.552737343\n",
       "ARTHRITIS     0.491007909  0.541346620\n",
       "DIABETES      0.365248731  0.481102829\n",
       "PAPTEST       0.299767393  0.328370276\n",
       "LPA           0.252989648  0.283959782\n",
       "CSMOKING      0.210323958  0.252452294\n",
       "BINGE         0.215034675  0.246098882\n",
       "ACCESS2       0.166763573  0.189340144\n",
       "HIGHCHOL      0.108607519  0.153973927\n",
       "MAMMOUSE      0.104546893  0.131711119\n",
       "COREM         0.068957156  0.095128395\n",
       "DENTAL       -0.041528601 -0.016551533\n",
       "BPMED        -0.047352980 -0.022700161\n",
       "COREW        -0.057143028 -0.030620363\n",
       "CHOLSCREEN   -0.171566985 -0.141674521\n",
       "COLON_SCREEN -0.180094221 -0.149905676\n",
       "CHECKUP      -0.225338784 -0.196016461\n",
       "SLEEP        -0.239482943 -0.212739187\n",
       "PHLTH        -1.080072540 -0.987533269\n",
       "CANCER       -1.226799885 -1.062754092\n",
       "STROKE       -1.518222865 -1.240522461\n",
       "CHD          -1.808064166 -1.579936603"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set the alpha for confidence interval sizes\n",
    "alpha = .05\n",
    "\n",
    "#Obtain Coefficient confidence intervals\n",
    "conf_ints = m1.conf_int(alpha=alpha)\n",
    "conf_ints.columns =['low','high']\n",
    "conf_ints.sort_values('high',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>It's no surprise to see High Blood Pressure (BPHIGH), Kidney Disease, and Arthritis high up on this list. According to the CDC<sup>1</sup>, these are all effects of being obese. What's extremely interesting is CHD (coronary heart disease) ranks as a strong indicator of populations low in obesity. Also, an outcome of Reported poor physical health is a strong indicator of populations with low obesity. The two data data series have a .89 correlation. I'll drop this one as well.</p>\n",
    "\n",
    "<p>Next, I'll remove those items typically associated as effects as obesity to see if we can narrow down some causes that may be closer to causing obesity</p>\n",
    "\n",
    "<p><sup>1</sup><a href='https://www.cdc.gov/healthyweight/effects/index.html'>CDC: The Health Effects of Overweight and Obesity</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC Change: 14789.8278\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                OBESITY   R-squared:                       0.989\n",
      "Model:                            OLS   Adj. R-squared:                  0.989\n",
      "Method:                 Least Squares   F-statistic:                 1.093e+05\n",
      "Date:                Tue, 10 Apr 2018   Prob (F-statistic):               0.00\n",
      "Time:                        09:30:08   Log-Likelihood:                 41255.\n",
      "No. Observations:               20398   AIC:                        -8.248e+04\n",
      "Df Residuals:                   20381   BIC:                        -8.234e+04\n",
      "Df Model:                          17                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "ACCESS2          0.0326      0.006      5.632      0.000       0.021       0.044\n",
      "BINGE            0.0033      0.010      0.330      0.742      -0.017       0.023\n",
      "BPMED            0.2338      0.007     32.334      0.000       0.220       0.248\n",
      "CANCER           0.1048      0.036      2.942      0.003       0.035       0.175\n",
      "CASTHMA          0.6945      0.032     21.811      0.000       0.632       0.757\n",
      "CHECKUP         -0.0572      0.009     -6.416      0.000      -0.075      -0.040\n",
      "CHOLSCREEN      -0.0927      0.010     -9.389      0.000      -0.112      -0.073\n",
      "COLON_SCREEN    -0.0158      0.010     -1.559      0.119      -0.036       0.004\n",
      "COPD            -0.3596      0.036    -10.010      0.000      -0.430      -0.289\n",
      "COREM            0.0226      0.009      2.538      0.011       0.005       0.040\n",
      "COREW            0.1154      0.009     12.752      0.000       0.098       0.133\n",
      "CSMOKING         0.4154      0.013     31.007      0.000       0.389       0.442\n",
      "DENTAL          -0.3507      0.007    -47.961      0.000      -0.365      -0.336\n",
      "LPA              0.2329      0.010     23.346      0.000       0.213       0.252\n",
      "MAMMOUSE         0.1227      0.009     13.272      0.000       0.105       0.141\n",
      "PAPTEST          0.2437      0.010     25.093      0.000       0.225       0.263\n",
      "SLEEP           -0.1760      0.009    -18.687      0.000      -0.195      -0.158\n",
      "==============================================================================\n",
      "Omnibus:                      220.506   Durbin-Watson:                   1.991\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              243.014\n",
      "Skew:                          -0.219   Prob(JB):                     1.70e-53\n",
      "Kurtosis:                       3.306   Cond. No.                         408.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Drop features with higher pvalues\n",
    "drop_effects_of_obesity = np.array(['CHD','BPHIGH','ARTHRITIS','DIABETES','HIGHCHOL','PHLTH','KIDNEY','STROKE'])\n",
    "Xtrain_dropped = Xtrain.drop(np.concatenate([drop_effects_of_obesity,drop_high_pval]),axis=1)\n",
    "\n",
    "# Retrain model without dropped features\n",
    "m2 = sm.OLS(ytrain,Xtrain_dropped).fit()\n",
    "print('AIC Change: {0:.4f}'.format(m2.aic-m1.aic))\n",
    "print(m2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> First, we see a drop in R2 from .995 to .989 and an AIC increase of 14789. This seems like a big increase but I'm willing to include it to reduce the noise from variables that are typically an effect of what we're trying to predict</h2>\n",
    "\n",
    "<h2> Second, We now see that the p value for populations with a higher % of colon_screenings and a higher % of binge drinking. Let's remove that and see what the outcome of these variables are</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC Change: -1.3431\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                OBESITY   R-squared:                       0.989\n",
      "Model:                            OLS   Adj. R-squared:                  0.989\n",
      "Method:                 Least Squares   F-statistic:                 1.239e+05\n",
      "Date:                Tue, 10 Apr 2018   Prob (F-statistic):               0.00\n",
      "Time:                        09:30:08   Log-Likelihood:                 41253.\n",
      "No. Observations:               20398   AIC:                        -8.248e+04\n",
      "Df Residuals:                   20383   BIC:                        -8.236e+04\n",
      "Df Model:                          15                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "ACCESS2        0.0352      0.006      6.312      0.000       0.024       0.046\n",
      "BPMED          0.2331      0.007     32.443      0.000       0.219       0.247\n",
      "CANCER         0.0979      0.035      2.780      0.005       0.029       0.167\n",
      "CASTHMA        0.6823      0.031     22.114      0.000       0.622       0.743\n",
      "CHECKUP       -0.0618      0.008     -7.316      0.000      -0.078      -0.045\n",
      "CHOLSCREEN    -0.0907      0.010     -9.313      0.000      -0.110      -0.072\n",
      "COPD          -0.3656      0.036    -10.242      0.000      -0.436      -0.296\n",
      "COREM          0.0215      0.009      2.473      0.013       0.004       0.039\n",
      "COREW          0.1104      0.008     13.379      0.000       0.094       0.127\n",
      "CSMOKING       0.4215      0.012     33.979      0.000       0.397       0.446\n",
      "DENTAL        -0.3531      0.006    -56.099      0.000      -0.365      -0.341\n",
      "LPA            0.2350      0.010     23.810      0.000       0.216       0.254\n",
      "MAMMOUSE       0.1203      0.009     13.348      0.000       0.103       0.138\n",
      "PAPTEST        0.2413      0.009     25.940      0.000       0.223       0.259\n",
      "SLEEP         -0.1758      0.009    -18.682      0.000      -0.194      -0.157\n",
      "==============================================================================\n",
      "Omnibus:                      218.235   Durbin-Watson:                   1.991\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              239.132\n",
      "Skew:                          -0.220   Prob(JB):                     1.18e-52\n",
      "Kurtosis:                       3.296   Cond. No.                         387.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "drop_high_pval2 = np.array(['BINGE','COLON_SCREEN'])\n",
    "Xtrain_dropped = Xtrain.drop(np.concatenate([drop_effects_of_obesity,drop_high_pval,drop_high_pval2]),axis=1)\n",
    "\n",
    "# Retrain model without dropped features\n",
    "m3 = sm.OLS(ytrain,Xtrain_dropped).fit()\n",
    "print('AIC Change: {0:.4f}'.format(m3.aic-m2.aic))\n",
    "print(m3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>We saw a tiny decrease to AIC and no change to our R^2</H2>\n",
    "\n",
    "<h3>Let's look at our coefficients</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CASTHMA</th>\n",
       "      <td>0.621850651</td>\n",
       "      <td>0.742809070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSMOKING</th>\n",
       "      <td>0.397214678</td>\n",
       "      <td>0.445847121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAPTEST</th>\n",
       "      <td>0.223031849</td>\n",
       "      <td>0.259492818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPA</th>\n",
       "      <td>0.215645616</td>\n",
       "      <td>0.254335557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPMED</th>\n",
       "      <td>0.218996327</td>\n",
       "      <td>0.247159740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CANCER</th>\n",
       "      <td>0.028865204</td>\n",
       "      <td>0.166892003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAMMOUSE</th>\n",
       "      <td>0.102622583</td>\n",
       "      <td>0.137949917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COREW</th>\n",
       "      <td>0.094223728</td>\n",
       "      <td>0.126570871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACCESS2</th>\n",
       "      <td>0.024244223</td>\n",
       "      <td>0.046084625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COREM</th>\n",
       "      <td>0.004462104</td>\n",
       "      <td>0.038575359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHECKUP</th>\n",
       "      <td>-0.078381608</td>\n",
       "      <td>-0.045255365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHOLSCREEN</th>\n",
       "      <td>-0.109752042</td>\n",
       "      <td>-0.071585166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLEEP</th>\n",
       "      <td>-0.194267107</td>\n",
       "      <td>-0.157372770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COPD</th>\n",
       "      <td>-0.435512042</td>\n",
       "      <td>-0.295590297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DENTAL</th>\n",
       "      <td>-0.365434214</td>\n",
       "      <td>-0.340759987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    low         high\n",
       "CASTHMA     0.621850651  0.742809070\n",
       "CSMOKING    0.397214678  0.445847121\n",
       "PAPTEST     0.223031849  0.259492818\n",
       "LPA         0.215645616  0.254335557\n",
       "BPMED       0.218996327  0.247159740\n",
       "CANCER      0.028865204  0.166892003\n",
       "MAMMOUSE    0.102622583  0.137949917\n",
       "COREW       0.094223728  0.126570871\n",
       "ACCESS2     0.024244223  0.046084625\n",
       "COREM       0.004462104  0.038575359\n",
       "CHECKUP    -0.078381608 -0.045255365\n",
       "CHOLSCREEN -0.109752042 -0.071585166\n",
       "SLEEP      -0.194267107 -0.157372770\n",
       "COPD       -0.435512042 -0.295590297\n",
       "DENTAL     -0.365434214 -0.340759987"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set the alpha for confidence interval sizes\n",
    "alpha = .05\n",
    "\n",
    "#Obtain Coefficient confidence intervals\n",
    "conf_ints = m3.conf_int(alpha=alpha)\n",
    "conf_ints.columns =['low','high']\n",
    "conf_ints.sort_values('high',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2> Some findings jump out off the screen. 1.) 2 out of 4 of the top 4 predictive features of populations with high obesity are negative behaviours. Being a smoker and having asthma are high predictive features of high obesity. The 5th, taking Blood pressure medication could be due to the correlation between obesity and high blood pressure, hence those populations would take blood pressure medication.</H2>\n",
    "\n",
    "<H3> There are a couple features which don't make a sense to me. First, populations that have had higher rates of pap smear tests among those who didn't have a hysterectomy are a strong indicator of high obesity. Contextually, this doesn't fit. Also, Populations with higher rates of COPD are indicators of lower rates of obesity. This could be due to collinearity</H3> \n",
    "\n",
    "<H4> I'd like to do a couple things at this point. Remove features that dont make sense contextually to increasing Obesity (Having a papsmear test, a mammogram, or the correlation between BPMED and OBESITY) and then perform a PCA to remove some of the collinearity that may be happening.</H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC Change: 2153.1789\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                OBESITY   R-squared:                       0.988\n",
      "Model:                            OLS   Adj. R-squared:                  0.988\n",
      "Method:                 Least Squares   F-statistic:                 1.392e+05\n",
      "Date:                Tue, 10 Apr 2018   Prob (F-statistic):               0.00\n",
      "Time:                        09:30:08   Log-Likelihood:                 40174.\n",
      "No. Observations:               20398   AIC:                        -8.032e+04\n",
      "Df Residuals:                   20386   BIC:                        -8.023e+04\n",
      "Df Model:                          12                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "ACCESS2        0.1654      0.005     36.015      0.000       0.156       0.174\n",
      "CANCER         0.2878      0.035      8.250      0.000       0.219       0.356\n",
      "CASTHMA        1.1165      0.030     37.727      0.000       1.058       1.174\n",
      "CHECKUP        0.0427      0.008      5.437      0.000       0.027       0.058\n",
      "CHOLSCREEN     0.2185      0.007     30.982      0.000       0.205       0.232\n",
      "COPD          -0.7301      0.035    -20.796      0.000      -0.799      -0.661\n",
      "COREM          0.0294      0.009      3.326      0.001       0.012       0.047\n",
      "COREW          0.1404      0.008     16.641      0.000       0.124       0.157\n",
      "CSMOKING       0.5648      0.013     45.024      0.000       0.540       0.589\n",
      "DENTAL        -0.2562      0.006    -44.869      0.000      -0.267      -0.245\n",
      "LPA            0.2338      0.009     25.572      0.000       0.216       0.252\n",
      "SLEEP         -0.1610      0.010    -16.854      0.000      -0.180      -0.142\n",
      "==============================================================================\n",
      "Omnibus:                      634.273   Durbin-Watson:                   1.997\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              780.770\n",
      "Skew:                          -0.377   Prob(JB):                    2.87e-170\n",
      "Kurtosis:                       3.591   Cond. No.                         265.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "drop_noncontext= np.array(['MAMMOUSE','PAPTEST','BPMED'])\n",
    "Xtrain_dropped = Xtrain.drop(np.concatenate([drop_effects_of_obesity,drop_high_pval,drop_high_pval2,drop_noncontext]),axis=1)\n",
    "\n",
    "# Retrain model without dropped features\n",
    "m4 = sm.OLS(ytrain,Xtrain_dropped).fit()\n",
    "print('AIC Change: {0:.4f}'.format(m4.aic-m3.aic))\n",
    "print(m4.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> We see a small drop in R2 from .989 to .988 and an AIC increase of 2153. It's not as bad as some of the other drops but it is fairly large.\n",
    "\n",
    "We still see COPD as a strong indicator of low obesity, in which the correlation between Obestity and COPD is high (.75). Let's perform PCA to see if we can reduce some collinearity.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.14813208e-01,   1.27158725e-01,   5.99467694e-02,\n",
       "         4.41207999e-02,   1.80706697e-02,   1.16031691e-02,\n",
       "         8.55377211e-03,   6.68148811e-03,   5.85873662e-03,\n",
       "         1.94021698e-03,   8.50057960e-04,   4.02386421e-04])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize and fit NMF\n",
    "pca = PCA()\n",
    "pca.fit(Xtrain_dropped)\n",
    "Xtrain_PCA = pca.transform(Xtrain_dropped)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC Change: 88950.6349\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                OBESITY   R-squared:                       0.055\n",
      "Model:                            OLS   Adj. R-squared:                  0.055\n",
      "Method:                 Least Squares   F-statistic:                     99.73\n",
      "Date:                Tue, 10 Apr 2018   Prob (F-statistic):          1.44e-241\n",
      "Time:                        09:30:09   Log-Likelihood:                -4301.7\n",
      "No. Observations:               20398   AIC:                             8627.\n",
      "Df Residuals:                   20386   BIC:                             8722.\n",
      "Df Model:                          12                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.2875      0.010     29.504      0.000       0.268       0.307\n",
      "x2            -0.2911      0.023    -12.599      0.000      -0.336      -0.246\n",
      "x3            -0.3497      0.034    -10.392      0.000      -0.416      -0.284\n",
      "x4            -0.0908      0.039     -2.314      0.021      -0.168      -0.014\n",
      "x5            -0.1228      0.061     -2.003      0.045      -0.243      -0.003\n",
      "x6             0.0487      0.076      0.637      0.524      -0.101       0.199\n",
      "x7            -0.1822      0.089     -2.045      0.041      -0.357      -0.008\n",
      "x8            -0.3746      0.101     -3.716      0.000      -0.572      -0.177\n",
      "x9            -0.2237      0.108     -2.078      0.038      -0.435      -0.013\n",
      "x10           -0.2053      0.187     -1.098      0.272      -0.572       0.161\n",
      "x11           -1.2685      0.283     -4.488      0.000      -1.822      -0.715\n",
      "x12            1.0136      0.411      2.467      0.014       0.208       1.819\n",
      "==============================================================================\n",
      "Omnibus:                      375.464   Durbin-Watson:                   0.025\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              410.343\n",
      "Skew:                          -0.309   Prob(JB):                     7.86e-90\n",
      "Kurtosis:                       3.316   Cond. No.                         42.1\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Retrain model without dropped features\n",
    "m5 = sm.OLS(ytrain,Xtrain_PCA).fit()\n",
    "print('AIC Change: {0:.4f}'.format(m5.aic-m4.aic))\n",
    "print(m5.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> PCA has no value to this data. Lets Try NFM </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC Change: 1467.9027\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                OBESITY   R-squared:                       0.987\n",
      "Model:                            OLS   Adj. R-squared:                  0.987\n",
      "Method:                 Least Squares   F-statistic:                 1.294e+05\n",
      "Date:                Tue, 10 Apr 2018   Prob (F-statistic):               0.00\n",
      "Time:                        09:30:11   Log-Likelihood:                 39440.\n",
      "No. Observations:               20398   AIC:                        -7.886e+04\n",
      "Df Residuals:                   20386   BIC:                        -7.876e+04\n",
      "Df Model:                          12                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.0618      0.001     50.793      0.000       0.059       0.064\n",
      "x2             1.3375      0.012    112.487      0.000       1.314       1.361\n",
      "x3             0.1548      0.004     40.456      0.000       0.147       0.162\n",
      "x4             0.1475      0.003     49.850      0.000       0.142       0.153\n",
      "x5             0.0182      0.001     12.923      0.000       0.015       0.021\n",
      "x6             1.1191      0.020     55.109      0.000       1.079       1.159\n",
      "x7             0.2777      0.006     43.566      0.000       0.265       0.290\n",
      "x8             0.2248      0.003     73.831      0.000       0.219       0.231\n",
      "x9            -0.0258      0.003     -7.393      0.000      -0.033      -0.019\n",
      "x10            0.0965      0.009     10.262      0.000       0.078       0.115\n",
      "x11            0.1798      0.006     30.201      0.000       0.168       0.191\n",
      "x12            0.2674      0.007     38.199      0.000       0.254       0.281\n",
      "==============================================================================\n",
      "Omnibus:                      775.334   Durbin-Watson:                   1.994\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1094.343\n",
      "Skew:                          -0.385   Prob(JB):                    2.33e-238\n",
      "Kurtosis:                       3.834   Cond. No.                         97.1\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "nmf = NMF()\n",
    "Xtrain_NMF = nmf.fit_transform(Xtrain_dropped)\n",
    "\n",
    "# Retrain model with NMF\n",
    "m5 = sm.OLS(ytrain,Xtrain_NMF).fit()\n",
    "print('AIC Change: {0:.4f}'.format(m5.aic-m4.aic))\n",
    "print(m5.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>It looks like there are three features that are most important to the model. Let's select them to see which inputs to the NMF are important to those Features</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xcc27438>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5YAAAE8CAYAAAC7Ey7fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npC4aWIqIiIiIiEhdNLAUERERERGRuvw/v7v9VTBo4KgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd1d8828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "fig = plt.figure(figsize=(18,5))\n",
    "sns.heatmap(pd.DataFrame(nmf.components_,columns=Xtrain_dropped.columns).iloc[[4,6,11],:],annot=True,cmap='inferno')\n",
    "plt.title('NMF Components')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Access to health insurance seems to be an important input as it hits two of these high effecient features. We also see some of the other causes that we noted earlier like low physical activity, being a smoker, and having asthma. It's interesting to note that Sleep is now coming in as well in the feature that has the highest coefficients</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Fold Validation with untouched data\n",
      "Linear Regression R2: 0.8267\n",
      "Linear Regression Cross Val Score: [ 0.82175699  0.82753836  0.83009496  0.83033927  0.82593027]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASTHMA</th>\n",
       "      <th>CSMOKING</th>\n",
       "      <th>ACCESS2</th>\n",
       "      <th>CANCER</th>\n",
       "      <th>CHOLSCREEN</th>\n",
       "      <th>LPA</th>\n",
       "      <th>COREW</th>\n",
       "      <th>COREM</th>\n",
       "      <th>CHECKUP</th>\n",
       "      <th>SLEEP</th>\n",
       "      <th>DENTAL</th>\n",
       "      <th>COPD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Coefs</th>\n",
       "      <td>1.396864051</td>\n",
       "      <td>0.621190599</td>\n",
       "      <td>0.311703723</td>\n",
       "      <td>0.304106784</td>\n",
       "      <td>0.278576687</td>\n",
       "      <td>0.185170561</td>\n",
       "      <td>0.104774905</td>\n",
       "      <td>0.080518520</td>\n",
       "      <td>0.015837058</td>\n",
       "      <td>-0.056606291</td>\n",
       "      <td>-0.125339555</td>\n",
       "      <td>-0.736287060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CASTHMA    CSMOKING     ACCESS2      CANCER  CHOLSCREEN         LPA  \\\n",
       "Coefs 1.396864051 0.621190599 0.311703723 0.304106784 0.278576687 0.185170561   \n",
       "\n",
       "            COREW       COREM     CHECKUP        SLEEP       DENTAL  \\\n",
       "Coefs 0.104774905 0.080518520 0.015837058 -0.056606291 -0.125339555   \n",
       "\n",
       "              COPD  \n",
       "Coefs -0.736287060  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scorer(model,X,y):\n",
    "    model.fit(X,y)\n",
    "    ypred = model.predict(X)\n",
    "    return r2_score(y,ypred)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(Xtrain_dropped,ytrain)\n",
    "print('Cross Fold Validation with untouched data')\n",
    "print('Linear Regression R2: {:.4f}'.format(lr.score(Xtrain_dropped,ytrain)))\n",
    "print('Linear Regression Cross Val Score: {}'.format(cross_val_score(lr,Xtrain_dropped,ytrain,cv=5,scoring=scorer)))\n",
    "pd.DataFrame(lr.coef_,index=Xtrain_dropped.columns,columns=['Coefs']).sort_values('Coefs',ascending=False).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Fold Validation With NMF data\n",
      "Linear Regression R2: 0.809\n",
      "Linear Regression Cross Val Score: [ 0.8028236   0.80965332  0.81215982  0.81173288  0.81308568]\n"
     ]
    }
   ],
   "source": [
    "#USING NMF\n",
    "lr_NMF = LinearRegression()\n",
    "lr_NMF.fit(Xtrain_NMF,ytrain)\n",
    "print('Cross Fold Validation With NMF data')\n",
    "print('Linear Regression R2: {:.3f}'.format(lr_NMF.score(Xtrain_NMF,ytrain)))\n",
    "print('Linear Regression Cross Val Score: {}'.format(cross_val_score(lr_NMF,Xtrain_NMF,ytrain,cv=5,scoring=scorer)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>It looks like the non decomposed data performs better. Let's see how it performs on the untouched data set</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Holdout Data Score: 0.831\n"
     ]
    }
   ],
   "source": [
    "Xtest_dropped = Xtest.drop(np.concatenate([drop_effects_of_obesity,drop_high_pval,drop_high_pval2,drop_noncontext]),axis=1)\n",
    "print('Linear Regression Holdout Data Score: {:.3f}'.format(r2_score(ytest,lr.predict(Xtest_dropped))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2> This model fits fairly well and is generalized very well too. The only way we'd want to change it is if we can get a better score. I'll try building with a Ridge Regression, Lasso, and a random forest</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GridSearchCV to find the best alpha in a Lasso regression\n",
      "Best Alpha: 0.0000\n",
      "Best Score: 0.8264\n"
     ]
    }
   ],
   "source": [
    "#filter out warnings for using alpha=0\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('Using GridSearchCV to find the best alpha in a Lasso regression')\n",
    "alphas = np.linspace(0,1,20)\n",
    "params = {'alpha':alphas}\n",
    "\n",
    "lasso = Lasso()\n",
    "grid = GridSearchCV(lasso,params,cv=5)\n",
    "grid.fit(Xtrain_dropped,ytrain)\n",
    "best_alpha = grid.best_params_['alpha']\n",
    "best_score = grid.best_score_\n",
    "print('Best Alpha: {:.4f}'.format(best_alpha))\n",
    "print('Best Score: {:.4f}'.format(best_score))\n",
    "warnings.filterwarnings('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>This is not a very good score and a closer look at the predicted values of the Xtraining data shows it doesn't fit to this data very well.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on holdout data: 0.8307\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "lasso = Lasso(alpha=best_alpha)\n",
    "lasso.fit(Xtrain_dropped,ytrain)\n",
    "ypred = lasso.predict(Xtrain_dropped)\n",
    "ypred = lasso.predict(Xtest_dropped)\n",
    "print('Score on holdout data: {:.4f}'.format(r2_score(ytest,ypred)))\n",
    "warnings.filterwarnings('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next, I'll use GridSearchCV with Ridge Regression to see if there is an optimum Alpha to obtain a better score\n",
      "Best Alpha: 0.0000\n",
      "Best Score: 0.8264\n"
     ]
    }
   ],
   "source": [
    "print('Next, I\\'ll use GridSearchCV with Ridge Regression to see if there is an optimum Alpha to obtain a better score')\n",
    "alphas = np.linspace(0,1,20)\n",
    "params = {'alpha':alphas}\n",
    "\n",
    "ridge = Ridge()\n",
    "grid = GridSearchCV(ridge,params,cv=5)\n",
    "grid.fit(Xtrain_dropped,ytrain)\n",
    "best_alpha = grid.best_params_['alpha']\n",
    "best_score = grid.best_score_\n",
    "print('Best Alpha: {:.4f}'.format(best_alpha))\n",
    "print('Best Score: {:.4f}'.format(best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>This score is almost identical to that of the the LinearRegression model with no alpha. In fact, when we compare it to the holdout data, we get almost the same score as on the Linear Regression as well. This is because the best alpha is 0 and is the same as a Linear Regression Model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Model Tested on Unseen Data\n",
      "Score on holdout data: 0.8307\n"
     ]
    }
   ],
   "source": [
    "print('Ridge Model Tested on Unseen Data')\n",
    "ridge = Ridge(alpha=best_alpha)\n",
    "ridge.fit(Xtrain_dropped,ytrain)\n",
    "ypred = ridge.predict(Xtest_dropped)\n",
    "print('Score on holdout data: {:.4f}'.format(r2_score(ytest,ypred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Finally, let's see how a random forests model fits this data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RS Score: 0.9852\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "randforest= RandomForestRegressor()\n",
    "randforest.fit(Xtrain_dropped,ytrain)\n",
    "ypred = randforest.predict(Xtrain_dropped)\n",
    "print('RS Score: {:.4f}'.format(r2_score(ytrain,ypred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Our random forests regressor fits the data very well. Let's see how it performs when we generalize it with Cross Validation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.97933849,  0.97792789,  0.9778797 ,  0.98025556,  0.98007792])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(randforest,Xtrain_dropped,ytrain,cv=5,scoring=scorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> It looks like it generalizes well too. </h2>\n",
    "\n",
    "<h2> While this is a better model than Linear Regression (LR), we may want to consider using the LR over this. We are able to get the output of the LR and specifically what may be causing the increases in % of the population that is Obese while with the random forest, we are not able to see the outputs of the model. </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
